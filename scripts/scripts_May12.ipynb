{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Images 2 database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Volumes/Projects/3drn\n"
     ]
    }
   ],
   "source": [
    "# test\n",
    "%cd '/Volumes/Projects/3drn'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature extractor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I20250512 22:32:03.387099 769081 misc.cc:44] \n",
      "==============================================================================\n",
      "Feature extraction\n",
      "==============================================================================\n",
      "I20250512 22:32:03.387295 769097 sift.cc:717] Creating Covariant SIFT CPU feature extractor\n",
      "I20250512 22:32:03.387297 769096 sift.cc:717] Creating Covariant SIFT CPU feature extractor\n",
      "I20250512 22:32:03.387307 769098 sift.cc:717] Creating Covariant SIFT CPU feature extractor\n",
      "I20250512 22:32:03.387315 769099 sift.cc:717] Creating Covariant SIFT CPU feature extractor\n",
      "I20250512 22:32:03.387317 769100 sift.cc:717] Creating Covariant SIFT CPU feature extractor\n",
      "I20250512 22:32:03.387323 769101 sift.cc:717] Creating Covariant SIFT CPU feature extractor\n",
      "I20250512 22:32:03.387331 769102 sift.cc:717] Creating Covariant SIFT CPU feature extractor\n",
      "I20250512 22:32:03.387333 769103 sift.cc:717] Creating Covariant SIFT CPU feature extractor\n",
      "I20250512 22:32:03.387338 769104 sift.cc:717] Creating Covariant SIFT CPU feature extractor\n",
      "I20250512 22:32:03.387342 769105 sift.cc:717] Creating Covariant SIFT CPU feature extractor\n",
      "I20250512 22:32:03.387347 769106 sift.cc:717] Creating Covariant SIFT CPU feature extractor\n",
      "I20250512 22:32:03.387351 769107 sift.cc:717] Creating Covariant SIFT CPU feature extractor\n",
      "I20250512 22:32:03.387355 769108 sift.cc:717] Creating Covariant SIFT CPU feature extractor\n",
      "I20250512 22:32:03.387360 769109 sift.cc:717] Creating Covariant SIFT CPU feature extractor\n",
      "I20250512 22:32:03.388718 769110 feature_extraction.cc:258] Processed file [1/60]\n",
      "I20250512 22:32:03.388725 769110 feature_extraction.cc:261]   Name:            frame_0000.png\n",
      "E20250512 22:32:03.388729 769110 feature_extraction.cc:265] frame_0000.png IMAGE_EXISTS: Features for image were already extracted.\n",
      "I20250512 22:32:03.388927 769110 feature_extraction.cc:258] Processed file [2/60]\n",
      "I20250512 22:32:03.388931 769110 feature_extraction.cc:261]   Name:            frame_0001.png\n",
      "E20250512 22:32:03.388933 769110 feature_extraction.cc:265] frame_0001.png IMAGE_EXISTS: Features for image were already extracted.\n",
      "I20250512 22:32:03.389184 769110 feature_extraction.cc:258] Processed file [3/60]\n",
      "I20250512 22:32:03.389192 769110 feature_extraction.cc:261]   Name:            frame_0002.png\n",
      "E20250512 22:32:03.389196 769110 feature_extraction.cc:265] frame_0002.png IMAGE_EXISTS: Features for image were already extracted.\n",
      "I20250512 22:32:03.389428 769110 feature_extraction.cc:258] Processed file [4/60]\n",
      "I20250512 22:32:03.389437 769110 feature_extraction.cc:261]   Name:            frame_0003.png\n",
      "E20250512 22:32:03.389441 769110 feature_extraction.cc:265] frame_0003.png IMAGE_EXISTS: Features for image were already extracted.\n",
      "I20250512 22:32:03.389544 769110 feature_extraction.cc:258] Processed file [5/60]\n",
      "I20250512 22:32:03.389547 769110 feature_extraction.cc:261]   Name:            frame_0004.png\n",
      "E20250512 22:32:03.389550 769110 feature_extraction.cc:265] frame_0004.png IMAGE_EXISTS: Features for image were already extracted.\n",
      "I20250512 22:32:03.389654 769110 feature_extraction.cc:258] Processed file [6/60]\n",
      "I20250512 22:32:03.389657 769110 feature_extraction.cc:261]   Name:            frame_0005.png\n",
      "E20250512 22:32:03.389660 769110 feature_extraction.cc:265] frame_0005.png IMAGE_EXISTS: Features for image were already extracted.\n",
      "I20250512 22:32:03.389906 769110 feature_extraction.cc:258] Processed file [7/60]\n",
      "I20250512 22:32:03.389911 769110 feature_extraction.cc:261]   Name:            frame_0006.png\n",
      "E20250512 22:32:03.389914 769110 feature_extraction.cc:265] frame_0006.png IMAGE_EXISTS: Features for image were already extracted.\n",
      "I20250512 22:32:03.390137 769110 feature_extraction.cc:258] Processed file [8/60]\n",
      "I20250512 22:32:03.390142 769110 feature_extraction.cc:261]   Name:            frame_0007.png\n",
      "E20250512 22:32:03.390146 769110 feature_extraction.cc:265] frame_0007.png IMAGE_EXISTS: Features for image were already extracted.\n",
      "I20250512 22:32:03.390379 769110 feature_extraction.cc:258] Processed file [9/60]\n",
      "I20250512 22:32:03.390383 769110 feature_extraction.cc:261]   Name:            frame_0008.png\n",
      "E20250512 22:32:03.390386 769110 feature_extraction.cc:265] frame_0008.png IMAGE_EXISTS: Features for image were already extracted.\n",
      "I20250512 22:32:03.390635 769110 feature_extraction.cc:258] Processed file [10/60]\n",
      "I20250512 22:32:03.390637 769110 feature_extraction.cc:261]   Name:            frame_0009.png\n",
      "E20250512 22:32:03.390640 769110 feature_extraction.cc:265] frame_0009.png IMAGE_EXISTS: Features for image were already extracted.\n",
      "I20250512 22:32:03.390758 769110 feature_extraction.cc:258] Processed file [11/60]\n",
      "I20250512 22:32:03.390761 769110 feature_extraction.cc:261]   Name:            frame_0010.png\n",
      "E20250512 22:32:03.390764 769110 feature_extraction.cc:265] frame_0010.png IMAGE_EXISTS: Features for image were already extracted.\n",
      "I20250512 22:32:03.390879 769110 feature_extraction.cc:258] Processed file [12/60]\n",
      "I20250512 22:32:03.390883 769110 feature_extraction.cc:261]   Name:            frame_0011.png\n",
      "E20250512 22:32:03.390887 769110 feature_extraction.cc:265] frame_0011.png IMAGE_EXISTS: Features for image were already extracted.\n",
      "I20250512 22:32:03.391012 769110 feature_extraction.cc:258] Processed file [13/60]\n",
      "I20250512 22:32:03.391016 769110 feature_extraction.cc:261]   Name:            frame_0012.png\n",
      "E20250512 22:32:03.391017 769110 feature_extraction.cc:265] frame_0012.png IMAGE_EXISTS: Features for image were already extracted.\n",
      "I20250512 22:32:03.391021 769110 feature_extraction.cc:258] Processed file [14/60]\n",
      "I20250512 22:32:03.391023 769110 feature_extraction.cc:261]   Name:            frame_0013.png\n",
      "E20250512 22:32:03.391026 769110 feature_extraction.cc:265] frame_0013.png IMAGE_EXISTS: Features for image were already extracted.\n",
      "I20250512 22:32:03.391029 769110 feature_extraction.cc:258] Processed file [15/60]\n",
      "I20250512 22:32:03.391031 769110 feature_extraction.cc:261]   Name:            frame_0014.png\n",
      "E20250512 22:32:03.391034 769110 feature_extraction.cc:265] frame_0014.png IMAGE_EXISTS: Features for image were already extracted.\n",
      "I20250512 22:32:03.391037 769110 feature_extraction.cc:258] Processed file [16/60]\n",
      "I20250512 22:32:03.391039 769110 feature_extraction.cc:261]   Name:            frame_0015.png\n",
      "E20250512 22:32:03.391053 769110 feature_extraction.cc:265] frame_0015.png IMAGE_EXISTS: Features for image were already extracted.\n",
      "I20250512 22:32:03.391183 769110 feature_extraction.cc:258] Processed file [17/60]\n",
      "I20250512 22:32:03.391186 769110 feature_extraction.cc:261]   Name:            frame_0016.png\n",
      "E20250512 22:32:03.391188 769110 feature_extraction.cc:265] frame_0016.png IMAGE_EXISTS: Features for image were already extracted.\n",
      "I20250512 22:32:03.391413 769110 feature_extraction.cc:258] Processed file [18/60]\n",
      "I20250512 22:32:03.391417 769110 feature_extraction.cc:261]   Name:            frame_0017.png\n",
      "E20250512 22:32:03.391419 769110 feature_extraction.cc:265] frame_0017.png IMAGE_EXISTS: Features for image were already extracted.\n",
      "I20250512 22:32:03.391531 769110 feature_extraction.cc:258] Processed file [19/60]\n",
      "I20250512 22:32:03.391534 769110 feature_extraction.cc:261]   Name:            frame_0018.png\n",
      "E20250512 22:32:03.391536 769110 feature_extraction.cc:265] frame_0018.png IMAGE_EXISTS: Features for image were already extracted.\n",
      "I20250512 22:32:03.391692 769110 feature_extraction.cc:258] Processed file [20/60]\n",
      "I20250512 22:32:03.391696 769110 feature_extraction.cc:261]   Name:            frame_0019.png\n",
      "E20250512 22:32:03.391698 769110 feature_extraction.cc:265] frame_0019.png IMAGE_EXISTS: Features for image were already extracted.\n",
      "I20250512 22:32:03.391808 769110 feature_extraction.cc:258] Processed file [21/60]\n",
      "I20250512 22:32:03.391811 769110 feature_extraction.cc:261]   Name:            frame_0020.png\n",
      "E20250512 22:32:03.391813 769110 feature_extraction.cc:265] frame_0020.png IMAGE_EXISTS: Features for image were already extracted.\n",
      "I20250512 22:32:03.392014 769110 feature_extraction.cc:258] Processed file [22/60]\n",
      "I20250512 22:32:03.392017 769110 feature_extraction.cc:261]   Name:            frame_0021.png\n",
      "E20250512 22:32:03.392020 769110 feature_extraction.cc:265] frame_0021.png IMAGE_EXISTS: Features for image were already extracted.\n",
      "I20250512 22:32:03.392335 769110 feature_extraction.cc:258] Processed file [23/60]\n",
      "I20250512 22:32:03.392339 769110 feature_extraction.cc:261]   Name:            frame_0022.png\n",
      "E20250512 22:32:03.392341 769110 feature_extraction.cc:265] frame_0022.png IMAGE_EXISTS: Features for image were already extracted.\n",
      "I20250512 22:32:03.392580 769110 feature_extraction.cc:258] Processed file [24/60]\n",
      "I20250512 22:32:03.392583 769110 feature_extraction.cc:261]   Name:            frame_0023.png\n",
      "E20250512 22:32:03.392585 769110 feature_extraction.cc:265] frame_0023.png IMAGE_EXISTS: Features for image were already extracted.\n",
      "I20250512 22:32:03.392588 769110 feature_extraction.cc:258] Processed file [25/60]\n",
      "I20250512 22:32:03.392590 769110 feature_extraction.cc:261]   Name:            frame_0024.png\n",
      "E20250512 22:32:03.392593 769110 feature_extraction.cc:265] frame_0024.png IMAGE_EXISTS: Features for image were already extracted.\n",
      "I20250512 22:32:03.392843 769110 feature_extraction.cc:258] Processed file [26/60]\n",
      "I20250512 22:32:03.392846 769110 feature_extraction.cc:261]   Name:            frame_0025.png\n",
      "E20250512 22:32:03.392848 769110 feature_extraction.cc:265] frame_0025.png IMAGE_EXISTS: Features for image were already extracted.\n",
      "I20250512 22:32:03.392851 769110 feature_extraction.cc:258] Processed file [27/60]\n",
      "I20250512 22:32:03.392853 769110 feature_extraction.cc:261]   Name:            frame_0026.png\n",
      "E20250512 22:32:03.392856 769110 feature_extraction.cc:265] frame_0026.png IMAGE_EXISTS: Features for image were already extracted.\n",
      "I20250512 22:32:03.393064 769110 feature_extraction.cc:258] Processed file [28/60]\n",
      "I20250512 22:32:03.393067 769110 feature_extraction.cc:261]   Name:            frame_0027.png\n",
      "E20250512 22:32:03.393069 769110 feature_extraction.cc:265] frame_0027.png IMAGE_EXISTS: Features for image were already extracted.\n",
      "I20250512 22:32:03.393072 769110 feature_extraction.cc:258] Processed file [29/60]\n",
      "I20250512 22:32:03.393074 769110 feature_extraction.cc:261]   Name:            frame_0028.png\n",
      "E20250512 22:32:03.393077 769110 feature_extraction.cc:265] frame_0028.png IMAGE_EXISTS: Features for image were already extracted.\n",
      "I20250512 22:32:03.393208 769110 feature_extraction.cc:258] Processed file [30/60]\n",
      "I20250512 22:32:03.393211 769110 feature_extraction.cc:261]   Name:            frame_0029.png\n",
      "E20250512 22:32:03.393213 769110 feature_extraction.cc:265] frame_0029.png IMAGE_EXISTS: Features for image were already extracted.\n",
      "I20250512 22:32:03.393327 769110 feature_extraction.cc:258] Processed file [31/60]\n",
      "I20250512 22:32:03.393330 769110 feature_extraction.cc:261]   Name:            frame_0030.png\n",
      "E20250512 22:32:03.393332 769110 feature_extraction.cc:265] frame_0030.png IMAGE_EXISTS: Features for image were already extracted.\n",
      "I20250512 22:32:03.393450 769110 feature_extraction.cc:258] Processed file [32/60]\n",
      "I20250512 22:32:03.393451 769110 feature_extraction.cc:261]   Name:            frame_0031.png\n",
      "E20250512 22:32:03.393455 769110 feature_extraction.cc:265] frame_0031.png IMAGE_EXISTS: Features for image were already extracted.\n",
      "I20250512 22:32:03.393476 769110 feature_extraction.cc:258] Processed file [33/60]\n",
      "I20250512 22:32:03.393479 769110 feature_extraction.cc:261]   Name:            frame_0032.png\n",
      "E20250512 22:32:03.393481 769110 feature_extraction.cc:265] frame_0032.png IMAGE_EXISTS: Features for image were already extracted.\n",
      "I20250512 22:32:03.393743 769110 feature_extraction.cc:258] Processed file [34/60]\n",
      "I20250512 22:32:03.393745 769110 feature_extraction.cc:261]   Name:            frame_0033.png\n",
      "E20250512 22:32:03.393748 769110 feature_extraction.cc:265] frame_0033.png IMAGE_EXISTS: Features for image were already extracted.\n",
      "I20250512 22:32:03.393958 769110 feature_extraction.cc:258] Processed file [35/60]\n",
      "I20250512 22:32:03.393960 769110 feature_extraction.cc:261]   Name:            frame_0034.png\n",
      "E20250512 22:32:03.393963 769110 feature_extraction.cc:265] frame_0034.png IMAGE_EXISTS: Features for image were already extracted.\n",
      "I20250512 22:32:03.394227 769110 feature_extraction.cc:258] Processed file [36/60]\n",
      "I20250512 22:32:03.394229 769110 feature_extraction.cc:261]   Name:            frame_0035.png\n",
      "E20250512 22:32:03.394232 769110 feature_extraction.cc:265] frame_0035.png IMAGE_EXISTS: Features for image were already extracted.\n",
      "I20250512 22:32:03.394256 769110 feature_extraction.cc:258] Processed file [37/60]\n",
      "I20250512 22:32:03.394259 769110 feature_extraction.cc:261]   Name:            frame_0036.png\n",
      "E20250512 22:32:03.394261 769110 feature_extraction.cc:265] frame_0036.png IMAGE_EXISTS: Features for image were already extracted.\n",
      "I20250512 22:32:03.394498 769110 feature_extraction.cc:258] Processed file [38/60]\n",
      "I20250512 22:32:03.394502 769110 feature_extraction.cc:261]   Name:            frame_0037.png\n",
      "E20250512 22:32:03.394505 769110 feature_extraction.cc:265] frame_0037.png IMAGE_EXISTS: Features for image were already extracted.\n",
      "I20250512 22:32:03.394762 769110 feature_extraction.cc:258] Processed file [39/60]\n",
      "I20250512 22:32:03.394767 769110 feature_extraction.cc:261]   Name:            frame_0038.png\n",
      "E20250512 22:32:03.394770 769110 feature_extraction.cc:265] frame_0038.png IMAGE_EXISTS: Features for image were already extracted.\n",
      "I20250512 22:32:03.394920 769110 feature_extraction.cc:258] Processed file [40/60]\n",
      "I20250512 22:32:03.394923 769110 feature_extraction.cc:261]   Name:            frame_0039.png\n",
      "E20250512 22:32:03.394927 769110 feature_extraction.cc:265] frame_0039.png IMAGE_EXISTS: Features for image were already extracted.\n",
      "I20250512 22:32:03.394929 769110 feature_extraction.cc:258] Processed file [41/60]\n",
      "I20250512 22:32:03.394932 769110 feature_extraction.cc:261]   Name:            frame_0040.png\n",
      "E20250512 22:32:03.394933 769110 feature_extraction.cc:265] frame_0040.png IMAGE_EXISTS: Features for image were already extracted.\n",
      "I20250512 22:32:03.395176 769110 feature_extraction.cc:258] Processed file [42/60]\n",
      "I20250512 22:32:03.395179 769110 feature_extraction.cc:261]   Name:            frame_0041.png\n",
      "E20250512 22:32:03.395182 769110 feature_extraction.cc:265] frame_0041.png IMAGE_EXISTS: Features for image were already extracted.\n",
      "I20250512 22:32:03.395431 769110 feature_extraction.cc:258] Processed file [43/60]\n",
      "I20250512 22:32:03.395435 769110 feature_extraction.cc:261]   Name:            frame_0042.png\n",
      "E20250512 22:32:03.395437 769110 feature_extraction.cc:265] frame_0042.png IMAGE_EXISTS: Features for image were already extracted.\n",
      "I20250512 22:32:03.395589 769110 feature_extraction.cc:258] Processed file [44/60]\n",
      "I20250512 22:32:03.395596 769110 feature_extraction.cc:261]   Name:            frame_0043.png\n",
      "E20250512 22:32:03.395598 769110 feature_extraction.cc:265] frame_0043.png IMAGE_EXISTS: Features for image were already extracted.\n",
      "I20250512 22:32:03.395645 769110 feature_extraction.cc:258] Processed file [45/60]\n",
      "I20250512 22:32:03.395648 769110 feature_extraction.cc:261]   Name:            frame_0044.png\n",
      "E20250512 22:32:03.395651 769110 feature_extraction.cc:265] frame_0044.png IMAGE_EXISTS: Features for image were already extracted.\n",
      "I20250512 22:32:03.395654 769110 feature_extraction.cc:258] Processed file [46/60]\n",
      "I20250512 22:32:03.395658 769110 feature_extraction.cc:261]   Name:            frame_0045.png\n",
      "E20250512 22:32:03.395659 769110 feature_extraction.cc:265] frame_0045.png IMAGE_EXISTS: Features for image were already extracted.\n",
      "I20250512 22:32:03.395678 769110 feature_extraction.cc:258] Processed file [47/60]\n",
      "I20250512 22:32:03.395681 769110 feature_extraction.cc:261]   Name:            frame_0046.png\n",
      "E20250512 22:32:03.395701 769110 feature_extraction.cc:265] frame_0046.png IMAGE_EXISTS: Features for image were already extracted.\n",
      "I20250512 22:32:03.395802 769110 feature_extraction.cc:258] Processed file [48/60]\n",
      "I20250512 22:32:03.395805 769110 feature_extraction.cc:261]   Name:            frame_0047.png\n",
      "E20250512 22:32:03.395808 769110 feature_extraction.cc:265] frame_0047.png IMAGE_EXISTS: Features for image were already extracted.\n",
      "I20250512 22:32:03.395957 769110 feature_extraction.cc:258] Processed file [49/60]\n",
      "I20250512 22:32:03.395960 769110 feature_extraction.cc:261]   Name:            frame_0048.png\n",
      "E20250512 22:32:03.395963 769110 feature_extraction.cc:265] frame_0048.png IMAGE_EXISTS: Features for image were already extracted.\n",
      "I20250512 22:32:03.396185 769110 feature_extraction.cc:258] Processed file [50/60]\n",
      "I20250512 22:32:03.396189 769110 feature_extraction.cc:261]   Name:            frame_0049.png\n",
      "E20250512 22:32:03.396193 769110 feature_extraction.cc:265] frame_0049.png IMAGE_EXISTS: Features for image were already extracted.\n",
      "I20250512 22:32:03.396334 769110 feature_extraction.cc:258] Processed file [51/60]\n",
      "I20250512 22:32:03.396338 769110 feature_extraction.cc:261]   Name:            frame_0050.png\n",
      "E20250512 22:32:03.396340 769110 feature_extraction.cc:265] frame_0050.png IMAGE_EXISTS: Features for image were already extracted.\n",
      "I20250512 22:32:03.396576 769110 feature_extraction.cc:258] Processed file [52/60]\n",
      "I20250512 22:32:03.396580 769110 feature_extraction.cc:261]   Name:            frame_0051.png\n",
      "E20250512 22:32:03.396584 769110 feature_extraction.cc:265] frame_0051.png IMAGE_EXISTS: Features for image were already extracted.\n",
      "I20250512 22:32:03.396781 769110 feature_extraction.cc:258] Processed file [53/60]\n",
      "I20250512 22:32:03.396785 769110 feature_extraction.cc:261]   Name:            frame_0052.png\n",
      "E20250512 22:32:03.396787 769110 feature_extraction.cc:265] frame_0052.png IMAGE_EXISTS: Features for image were already extracted.\n",
      "I20250512 22:32:03.397019 769110 feature_extraction.cc:258] Processed file [54/60]\n",
      "I20250512 22:32:03.397023 769110 feature_extraction.cc:261]   Name:            frame_0053.png\n",
      "E20250512 22:32:03.397027 769110 feature_extraction.cc:265] frame_0053.png IMAGE_EXISTS: Features for image were already extracted.\n",
      "I20250512 22:32:03.397276 769110 feature_extraction.cc:258] Processed file [55/60]\n",
      "I20250512 22:32:03.397279 769110 feature_extraction.cc:261]   Name:            frame_0054.png\n",
      "E20250512 22:32:03.397281 769110 feature_extraction.cc:265] frame_0054.png IMAGE_EXISTS: Features for image were already extracted.\n",
      "I20250512 22:32:03.397308 769110 feature_extraction.cc:258] Processed file [56/60]\n",
      "I20250512 22:32:03.397311 769110 feature_extraction.cc:261]   Name:            frame_0055.png\n",
      "E20250512 22:32:03.397313 769110 feature_extraction.cc:265] frame_0055.png IMAGE_EXISTS: Features for image were already extracted.\n",
      "I20250512 22:32:03.397320 769110 feature_extraction.cc:258] Processed file [57/60]\n",
      "I20250512 22:32:03.397323 769110 feature_extraction.cc:261]   Name:            frame_0056.png\n",
      "E20250512 22:32:03.397326 769110 feature_extraction.cc:265] frame_0056.png IMAGE_EXISTS: Features for image were already extracted.\n",
      "I20250512 22:32:03.397572 769110 feature_extraction.cc:258] Processed file [58/60]\n",
      "I20250512 22:32:03.397576 769110 feature_extraction.cc:261]   Name:            frame_0057.png\n",
      "E20250512 22:32:03.397579 769110 feature_extraction.cc:265] frame_0057.png IMAGE_EXISTS: Features for image were already extracted.\n",
      "I20250512 22:32:03.397847 769110 feature_extraction.cc:258] Processed file [59/60]\n",
      "I20250512 22:32:03.397851 769110 feature_extraction.cc:261]   Name:            frame_0058.png\n",
      "E20250512 22:32:03.397853 769110 feature_extraction.cc:265] frame_0058.png IMAGE_EXISTS: Features for image were already extracted.\n",
      "I20250512 22:32:03.398165 769110 feature_extraction.cc:258] Processed file [60/60]\n",
      "I20250512 22:32:03.398171 769110 feature_extraction.cc:261]   Name:            frame_0059.png\n",
      "E20250512 22:32:03.398175 769110 feature_extraction.cc:265] frame_0059.png IMAGE_EXISTS: Features for image were already extracted.\n",
      "I20250512 22:32:03.398370 769081 timer.cc:91] Elapsed time: 0.000 [minutes]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "DATASET_PATH = 'data/xe_F1_khan_60_test2'\n",
    "assert os.path.exists(DATASET_PATH), f\"Dataset path {DATASET_PATH} does not exist.\"\n",
    "\n",
    "!colmap feature_extractor \\\n",
    "    --database_path $DATASET_PATH/database.db \\\n",
    "    --image_path $DATASET_PATH/images \\\n",
    "    --SiftExtraction.max_num_features 6144 \\\n",
    "    --SiftExtraction.max_image_size 2000 \\\n",
    "    --SiftExtraction.estimate_affine_shape 1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'data/xe_F1_khan_60'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DATASET_PATH"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exhausive matcher"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I20250416 23:02:00.509509 8308591 misc.cc:44] \n",
      "==============================================================================\n",
      "Feature matching\n",
      "==============================================================================\n",
      "I20250416 23:02:00.522176 8308592 sift.cc:1426] Creating SIFT GPU feature matcher\n",
      "I20250416 23:02:00.544878 8308591 pairing.cc:168] Generating exhaustive image pairs...\n",
      "I20250416 23:02:00.544893 8308591 pairing.cc:201] Matching block [1/2, 1/2]\n",
      "I20250416 23:02:04.256991 8308591 feature_matching.cc:46] in 3.712s\n",
      "I20250416 23:02:04.258081 8308591 pairing.cc:201] Matching block [1/2, 2/2]\n",
      "I20250416 23:02:04.406284 8308591 feature_matching.cc:46] in 0.148s\n",
      "I20250416 23:02:04.406589 8308591 pairing.cc:201] Matching block [2/2, 1/2]\n",
      "I20250416 23:02:05.772403 8308591 feature_matching.cc:46] in 1.366s\n",
      "I20250416 23:02:05.775379 8308591 pairing.cc:201] Matching block [2/2, 2/2]\n",
      "I20250416 23:02:05.906663 8308591 feature_matching.cc:46] in 0.131s\n",
      "I20250416 23:02:05.906852 8308591 timer.cc:91] Elapsed time: 0.090 [minutes]\n"
     ]
    }
   ],
   "source": [
    "assert os.path.exists(f\"{DATASET_PATH}/database.db\"), \"Database file was not created.\"\n",
    "assert os.path.exists(f\"{DATASET_PATH}/images\"), \"Images directory was not created.\"\n",
    "temp_path = f\"{DATASET_PATH}/database.db\"\n",
    "!colmap exhaustive_matcher \\\n",
    "    --database_path $temp_path \\\n",
    "    --SiftMatching.max_ratio 0.85\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sparse reconstruction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I20250512 22:32:13.126223 769273 incremental_pipeline.cc:251] Loading database\n",
      "I20250512 22:32:13.128191 769273 database_cache.cc:66] Loading cameras...\n",
      "I20250512 22:32:13.128225 769273 database_cache.cc:76]  60 in 0.000s\n",
      "I20250512 22:32:13.128232 769273 database_cache.cc:84] Loading matches...\n",
      "I20250512 22:32:13.140194 769273 database_cache.cc:89]  1766 in 0.012s\n",
      "I20250512 22:32:13.140205 769273 database_cache.cc:105] Loading images...\n",
      "I20250512 22:32:13.157604 769273 database_cache.cc:153]  60 in 0.017s (connected 60)\n",
      "I20250512 22:32:13.157614 769273 database_cache.cc:164] Loading pose priors...\n",
      "I20250512 22:32:13.157727 769273 database_cache.cc:175]  0 in 0.000s\n",
      "I20250512 22:32:13.157732 769273 database_cache.cc:184] Building correspondence graph...\n",
      "I20250512 22:32:13.173105 769273 database_cache.cc:210]  in 0.015s (ignored 0)\n",
      "I20250512 22:32:13.173276 769273 timer.cc:91] Elapsed time: 0.001 [minutes]\n",
      "I20250512 22:32:13.174991 769273 incremental_pipeline.cc:297] Finding good initial image pair\n",
      "I20250512 22:32:13.199332 769273 incremental_pipeline.cc:321] Initializing with image pair #10 and #12\n",
      "I20250512 22:32:13.200268 769273 incremental_pipeline.cc:326] Global bundle adjustment\n",
      "W20250512 22:32:13.241343 769273 incremental_pipeline.cc:55] Could not read image frame_0002.png at path data/xe_F1_khan_60_test2/images_test.\n",
      "I20250512 22:32:13.241366 769273 incremental_pipeline.cc:405] Registering image #13 (3)\n",
      "I20250512 22:32:13.241371 769273 incremental_pipeline.cc:408] => Image sees 423 / 2507 points\n",
      "I20250512 22:32:13.296494 769273 incremental_pipeline.cc:42] Retriangulation and Global bundle adjustment\n",
      "W20250512 22:32:13.419078 769273 incremental_pipeline.cc:55] Could not read image frame_0001.png at path data/xe_F1_khan_60_test2/images_test.\n",
      "I20250512 22:32:13.419111 769273 incremental_pipeline.cc:405] Registering image #1 (4)\n",
      "I20250512 22:32:13.419117 769273 incremental_pipeline.cc:408] => Image sees 970 / 2217 points\n",
      "I20250512 22:32:13.497591 769273 incremental_pipeline.cc:42] Retriangulation and Global bundle adjustment\n",
      "I20250512 22:32:13.542815 769273 incremental_pipeline.cc:405] Registering image #9 (5)\n",
      "I20250512 22:32:13.542832 769273 incremental_pipeline.cc:408] => Image sees 1213 / 2221 points\n",
      "I20250512 22:32:13.680197 769273 incremental_pipeline.cc:42] Retriangulation and Global bundle adjustment\n",
      "W20250512 22:32:13.767436 769273 incremental_pipeline.cc:55] Could not read image frame_0003.png at path data/xe_F1_khan_60_test2/images_test.\n",
      "I20250512 22:32:13.767463 769273 incremental_pipeline.cc:405] Registering image #11 (6)\n",
      "I20250512 22:32:13.767468 769273 incremental_pipeline.cc:408] => Image sees 1265 / 2102 points\n",
      "I20250512 22:32:13.898849 769273 incremental_pipeline.cc:42] Retriangulation and Global bundle adjustment\n",
      "W20250512 22:32:13.967584 769273 incremental_pipeline.cc:55] Could not read image frame_0004.png at path data/xe_F1_khan_60_test2/images_test.\n",
      "I20250512 22:32:13.967610 769273 incremental_pipeline.cc:405] Registering image #21 (7)\n",
      "I20250512 22:32:13.967615 769273 incremental_pipeline.cc:408] => Image sees 1118 / 2121 points\n",
      "I20250512 22:32:14.060572 769273 incremental_pipeline.cc:42] Retriangulation and Global bundle adjustment\n",
      "W20250512 22:32:14.173095 769273 incremental_pipeline.cc:55] Could not read image frame_0006.png at path data/xe_F1_khan_60_test2/images_test.\n",
      "I20250512 22:32:14.173125 769273 incremental_pipeline.cc:405] Registering image #15 (8)\n",
      "I20250512 22:32:14.173130 769273 incremental_pipeline.cc:408] => Image sees 1009 / 2039 points\n",
      "I20250512 22:32:14.257086 769273 incremental_pipeline.cc:42] Retriangulation and Global bundle adjustment\n",
      "W20250512 22:32:14.337517 769273 incremental_pipeline.cc:55] Could not read image frame_0007.png at path data/xe_F1_khan_60_test2/images_test.\n",
      "I20250512 22:32:14.337543 769273 incremental_pipeline.cc:405] Registering image #6 (9)\n",
      "I20250512 22:32:14.337548 769273 incremental_pipeline.cc:408] => Image sees 975 / 1921 points\n",
      "I20250512 22:32:14.425324 769273 incremental_pipeline.cc:42] Retriangulation and Global bundle adjustment\n",
      "I20250512 22:32:14.546581 769273 incremental_pipeline.cc:405] Registering image #20 (10)\n",
      "I20250512 22:32:14.546599 769273 incremental_pipeline.cc:408] => Image sees 992 / 1771 points\n",
      "I20250512 22:32:14.635107 769273 incremental_pipeline.cc:42] Retriangulation and Global bundle adjustment\n",
      "W20250512 22:32:14.751533 769273 incremental_pipeline.cc:55] Could not read image frame_0009.png at path data/xe_F1_khan_60_test2/images_test.\n",
      "I20250512 22:32:14.751556 769273 incremental_pipeline.cc:405] Registering image #14 (11)\n",
      "I20250512 22:32:14.751560 769273 incremental_pipeline.cc:408] => Image sees 879 / 1550 points\n",
      "I20250512 22:32:14.887854 769273 incremental_pipeline.cc:42] Retriangulation and Global bundle adjustment\n",
      "W20250512 22:32:15.001788 769273 incremental_pipeline.cc:55] Could not read image frame_0010.png at path data/xe_F1_khan_60_test2/images_test.\n",
      "I20250512 22:32:15.001816 769273 incremental_pipeline.cc:405] Registering image #60 (12)\n",
      "I20250512 22:32:15.001821 769273 incremental_pipeline.cc:408] => Image sees 678 / 1466 points\n",
      "W20250512 22:32:15.105285 769273 incremental_pipeline.cc:55] Could not read image frame_0059.png at path data/xe_F1_khan_60_test2/images_test.\n",
      "I20250512 22:32:15.105311 769273 incremental_pipeline.cc:405] Registering image #17 (13)\n",
      "I20250512 22:32:15.105317 769273 incremental_pipeline.cc:408] => Image sees 616 / 1370 points\n",
      "I20250512 22:32:15.178815 769273 incremental_pipeline.cc:42] Retriangulation and Global bundle adjustment\n",
      "W20250512 22:32:15.352550 769273 incremental_pipeline.cc:55] Could not read image frame_0011.png at path data/xe_F1_khan_60_test2/images_test.\n",
      "I20250512 22:32:15.352576 769273 incremental_pipeline.cc:405] Registering image #59 (14)\n",
      "I20250512 22:32:15.352581 769273 incremental_pipeline.cc:408] => Image sees 573 / 1651 points\n",
      "W20250512 22:32:15.448483 769273 incremental_pipeline.cc:55] Could not read image frame_0058.png at path data/xe_F1_khan_60_test2/images_test.\n",
      "I20250512 22:32:15.448504 769273 incremental_pipeline.cc:405] Registering image #58 (15)\n",
      "I20250512 22:32:15.448509 769273 incremental_pipeline.cc:408] => Image sees 748 / 1804 points\n",
      "I20250512 22:32:15.478752 769273 incremental_pipeline.cc:42] Retriangulation and Global bundle adjustment\n",
      "W20250512 22:32:15.604987 769273 incremental_pipeline.cc:55] Could not read image frame_0057.png at path data/xe_F1_khan_60_test2/images_test.\n",
      "I20250512 22:32:15.605011 769273 incremental_pipeline.cc:405] Registering image #8 (16)\n",
      "I20250512 22:32:15.605017 769273 incremental_pipeline.cc:408] => Image sees 643 / 1696 points\n",
      "I20250512 22:32:15.719477 769273 incremental_pipeline.cc:405] Registering image #57 (17)\n",
      "I20250512 22:32:15.719497 769273 incremental_pipeline.cc:408] => Image sees 712 / 1443 points\n",
      "I20250512 22:32:15.813237 769273 incremental_pipeline.cc:42] Retriangulation and Global bundle adjustment\n",
      "W20250512 22:32:15.944168 769273 incremental_pipeline.cc:55] Could not read image frame_0055.png at path data/xe_F1_khan_60_test2/images_test.\n",
      "I20250512 22:32:15.944191 769273 incremental_pipeline.cc:405] Registering image #56 (18)\n",
      "I20250512 22:32:15.944196 769273 incremental_pipeline.cc:408] => Image sees 636 / 1208 points\n",
      "W20250512 22:32:16.034631 769273 incremental_pipeline.cc:55] Could not read image frame_0054.png at path data/xe_F1_khan_60_test2/images_test.\n",
      "I20250512 22:32:16.034653 769273 incremental_pipeline.cc:405] Registering image #55 (19)\n",
      "I20250512 22:32:16.034658 769273 incremental_pipeline.cc:408] => Image sees 455 / 1079 points\n",
      "I20250512 22:32:16.122450 769273 incremental_pipeline.cc:42] Retriangulation and Global bundle adjustment\n",
      "W20250512 22:32:16.247069 769273 incremental_pipeline.cc:55] Could not read image frame_0053.png at path data/xe_F1_khan_60_test2/images_test.\n",
      "I20250512 22:32:16.247097 769273 incremental_pipeline.cc:405] Registering image #18 (20)\n",
      "I20250512 22:32:16.247102 769273 incremental_pipeline.cc:408] => Image sees 523 / 1589 points\n",
      "W20250512 22:32:16.318943 769273 incremental_pipeline.cc:55] Could not read image frame_0012.png at path data/xe_F1_khan_60_test2/images_test.\n",
      "I20250512 22:32:16.318969 769273 incremental_pipeline.cc:405] Registering image #19 (21)\n",
      "I20250512 22:32:16.318974 769273 incremental_pipeline.cc:408] => Image sees 631 / 1677 points\n",
      "I20250512 22:32:16.416148 769273 incremental_pipeline.cc:42] Retriangulation and Global bundle adjustment\n",
      "W20250512 22:32:16.519116 769273 incremental_pipeline.cc:55] Could not read image frame_0013.png at path data/xe_F1_khan_60_test2/images_test.\n",
      "I20250512 22:32:16.519145 769273 incremental_pipeline.cc:405] Registering image #16 (21)\n",
      "I20250512 22:32:16.519150 769273 incremental_pipeline.cc:408] => Image sees 824 / 1615 points\n",
      "W20250512 22:32:16.586210 769273 incremental_pipeline.cc:55] Could not read image frame_0014.png at path data/xe_F1_khan_60_test2/images_test.\n",
      "I20250512 22:32:16.586233 769273 incremental_pipeline.cc:405] Registering image #22 (22)\n",
      "I20250512 22:32:16.586237 769273 incremental_pipeline.cc:408] => Image sees 811 / 1502 points\n",
      "I20250512 22:32:16.685422 769273 incremental_pipeline.cc:42] Retriangulation and Global bundle adjustment\n",
      "W20250512 22:32:16.805207 769273 incremental_pipeline.cc:55] Could not read image frame_0015.png at path data/xe_F1_khan_60_test2/images_test.\n",
      "I20250512 22:32:16.805230 769273 incremental_pipeline.cc:405] Registering image #4 (23)\n",
      "I20250512 22:32:16.805235 769273 incremental_pipeline.cc:408] => Image sees 810 / 1522 points\n",
      "I20250512 22:32:16.913758 769273 incremental_pipeline.cc:405] Registering image #23 (24)\n",
      "I20250512 22:32:16.913774 769273 incremental_pipeline.cc:408] => Image sees 745 / 1625 points\n",
      "W20250512 22:32:17.026837 769273 incremental_pipeline.cc:55] Could not read image frame_0017.png at path data/xe_F1_khan_60_test2/images_test.\n",
      "I20250512 22:32:17.026865 769273 incremental_pipeline.cc:405] Registering image #24 (25)\n",
      "I20250512 22:32:17.026870 769273 incremental_pipeline.cc:408] => Image sees 775 / 1563 points\n",
      "I20250512 22:32:17.137275 769273 incremental_pipeline.cc:42] Retriangulation and Global bundle adjustment\n",
      "W20250512 22:32:17.260744 769273 incremental_pipeline.cc:55] Could not read image frame_0018.png at path data/xe_F1_khan_60_test2/images_test.\n",
      "I20250512 22:32:17.260771 769273 incremental_pipeline.cc:405] Registering image #25 (26)\n",
      "I20250512 22:32:17.260775 769273 incremental_pipeline.cc:408] => Image sees 827 / 1461 points\n",
      "W20250512 22:32:17.367244 769273 incremental_pipeline.cc:55] Could not read image frame_0019.png at path data/xe_F1_khan_60_test2/images_test.\n",
      "I20250512 22:32:17.367269 769273 incremental_pipeline.cc:405] Registering image #26 (27)\n",
      "I20250512 22:32:17.367272 769273 incremental_pipeline.cc:408] => Image sees 766 / 1452 points\n",
      "W20250512 22:32:17.475455 769273 incremental_pipeline.cc:55] Could not read image frame_0020.png at path data/xe_F1_khan_60_test2/images_test.\n",
      "I20250512 22:32:17.475481 769273 incremental_pipeline.cc:405] Registering image #29 (28)\n",
      "I20250512 22:32:17.475486 769273 incremental_pipeline.cc:408] => Image sees 706 / 1562 points\n",
      "I20250512 22:32:17.580775 769273 incremental_pipeline.cc:42] Retriangulation and Global bundle adjustment\n",
      "W20250512 22:32:17.718252 769273 incremental_pipeline.cc:55] Could not read image frame_0021.png at path data/xe_F1_khan_60_test2/images_test.\n",
      "I20250512 22:32:17.718281 769273 incremental_pipeline.cc:405] Registering image #30 (29)\n",
      "I20250512 22:32:17.718286 769273 incremental_pipeline.cc:408] => Image sees 728 / 1741 points\n",
      "W20250512 22:32:17.821754 769273 incremental_pipeline.cc:55] Could not read image frame_0022.png at path data/xe_F1_khan_60_test2/images_test.\n",
      "I20250512 22:32:17.821785 769273 incremental_pipeline.cc:405] Registering image #34 (30)\n",
      "I20250512 22:32:17.821791 769273 incremental_pipeline.cc:408] => Image sees 884 / 1903 points\n",
      "W20250512 22:32:17.933344 769273 incremental_pipeline.cc:55] Could not read image frame_0023.png at path data/xe_F1_khan_60_test2/images_test.\n",
      "I20250512 22:32:17.933369 769273 incremental_pipeline.cc:405] Registering image #7 (31)\n",
      "I20250512 22:32:17.933374 769273 incremental_pipeline.cc:408] => Image sees 1110 / 2023 points\n",
      "I20250512 22:32:18.039463 769273 incremental_pipeline.cc:42] Retriangulation and Global bundle adjustment\n",
      "I20250512 22:32:18.217614 769273 incremental_pipeline.cc:405] Registering image #32 (32)\n",
      "I20250512 22:32:18.217634 769273 incremental_pipeline.cc:408] => Image sees 1190 / 1932 points\n",
      "W20250512 22:32:18.328249 769273 incremental_pipeline.cc:55] Could not read image frame_0025.png at path data/xe_F1_khan_60_test2/images_test.\n",
      "I20250512 22:32:18.328279 769273 incremental_pipeline.cc:405] Registering image #31 (33)\n",
      "I20250512 22:32:18.328285 769273 incremental_pipeline.cc:408] => Image sees 1069 / 1782 points\n",
      "W20250512 22:32:18.465811 769273 incremental_pipeline.cc:55] Could not read image frame_0026.png at path data/xe_F1_khan_60_test2/images_test.\n",
      "I20250512 22:32:18.465831 769273 incremental_pipeline.cc:405] Registering image #35 (34)\n",
      "I20250512 22:32:18.465837 769273 incremental_pipeline.cc:408] => Image sees 930 / 1686 points\n",
      "W20250512 22:32:18.598614 769273 incremental_pipeline.cc:55] Could not read image frame_0027.png at path data/xe_F1_khan_60_test2/images_test.\n",
      "I20250512 22:32:18.598637 769273 incremental_pipeline.cc:405] Registering image #28 (35)\n",
      "I20250512 22:32:18.598642 769273 incremental_pipeline.cc:408] => Image sees 809 / 1521 points\n",
      "I20250512 22:32:18.721901 769273 incremental_pipeline.cc:42] Retriangulation and Global bundle adjustment\n",
      "W20250512 22:32:18.916283 769273 incremental_pipeline.cc:55] Could not read image frame_0028.png at path data/xe_F1_khan_60_test2/images_test.\n",
      "I20250512 22:32:18.916309 769273 incremental_pipeline.cc:405] Registering image #27 (36)\n",
      "I20250512 22:32:18.916314 769273 incremental_pipeline.cc:408] => Image sees 811 / 1551 points\n",
      "W20250512 22:32:19.034982 769273 incremental_pipeline.cc:55] Could not read image frame_0029.png at path data/xe_F1_khan_60_test2/images_test.\n",
      "I20250512 22:32:19.035004 769273 incremental_pipeline.cc:405] Registering image #33 (37)\n",
      "I20250512 22:32:19.035009 769273 incremental_pipeline.cc:408] => Image sees 948 / 1704 points\n",
      "W20250512 22:32:19.154109 769273 incremental_pipeline.cc:55] Could not read image frame_0030.png at path data/xe_F1_khan_60_test2/images_test.\n",
      "I20250512 22:32:19.154136 769273 incremental_pipeline.cc:405] Registering image #36 (38)\n",
      "I20250512 22:32:19.154142 769273 incremental_pipeline.cc:408] => Image sees 974 / 1721 points\n",
      "W20250512 22:32:19.289016 769273 incremental_pipeline.cc:55] Could not read image frame_0031.png at path data/xe_F1_khan_60_test2/images_test.\n",
      "I20250512 22:32:19.289040 769273 incremental_pipeline.cc:405] Registering image #5 (39)\n",
      "I20250512 22:32:19.289044 769273 incremental_pipeline.cc:408] => Image sees 963 / 1657 points\n",
      "I20250512 22:32:19.417301 769273 incremental_pipeline.cc:42] Retriangulation and Global bundle adjustment\n",
      "I20250512 22:32:19.653944 769273 incremental_pipeline.cc:405] Registering image #37 (40)\n",
      "I20250512 22:32:19.653965 769273 incremental_pipeline.cc:408] => Image sees 916 / 1443 points\n",
      "W20250512 22:32:19.778606 769273 incremental_pipeline.cc:55] Could not read image frame_0033.png at path data/xe_F1_khan_60_test2/images_test.\n",
      "I20250512 22:32:19.778630 769273 incremental_pipeline.cc:405] Registering image #39 (41)\n",
      "I20250512 22:32:19.778635 769273 incremental_pipeline.cc:408] => Image sees 808 / 1263 points\n",
      "W20250512 22:32:19.900635 769273 incremental_pipeline.cc:55] Could not read image frame_0034.png at path data/xe_F1_khan_60_test2/images_test.\n",
      "I20250512 22:32:19.900660 769273 incremental_pipeline.cc:405] Registering image #38 (42)\n",
      "I20250512 22:32:19.900664 769273 incremental_pipeline.cc:408] => Image sees 621 / 1229 points\n",
      "W20250512 22:32:20.007943 769273 incremental_pipeline.cc:55] Could not read image frame_0035.png at path data/xe_F1_khan_60_test2/images_test.\n",
      "I20250512 22:32:20.008055 769273 incremental_pipeline.cc:405] Registering image #40 (43)\n",
      "I20250512 22:32:20.008062 769273 incremental_pipeline.cc:408] => Image sees 586 / 1298 points\n",
      "I20250512 22:32:20.112707 769273 incremental_pipeline.cc:42] Retriangulation and Global bundle adjustment\n",
      "W20250512 22:32:20.367100 769273 incremental_pipeline.cc:55] Could not read image frame_0036.png at path data/xe_F1_khan_60_test2/images_test.\n",
      "I20250512 22:32:20.367125 769273 incremental_pipeline.cc:405] Registering image #45 (44)\n",
      "I20250512 22:32:20.367129 769273 incremental_pipeline.cc:408] => Image sees 727 / 1357 points\n",
      "W20250512 22:32:20.465384 769273 incremental_pipeline.cc:55] Could not read image frame_0037.png at path data/xe_F1_khan_60_test2/images_test.\n",
      "I20250512 22:32:20.465406 769273 incremental_pipeline.cc:405] Registering image #41 (45)\n",
      "I20250512 22:32:20.465411 769273 incremental_pipeline.cc:408] => Image sees 734 / 1303 points\n",
      "W20250512 22:32:20.561306 769273 incremental_pipeline.cc:55] Could not read image frame_0038.png at path data/xe_F1_khan_60_test2/images_test.\n",
      "I20250512 22:32:20.561331 769273 incremental_pipeline.cc:405] Registering image #42 (46)\n",
      "I20250512 22:32:20.561336 769273 incremental_pipeline.cc:408] => Image sees 679 / 1120 points\n",
      "W20250512 22:32:20.651171 769273 incremental_pipeline.cc:55] Could not read image frame_0039.png at path data/xe_F1_khan_60_test2/images_test.\n",
      "I20250512 22:32:20.651196 769273 incremental_pipeline.cc:405] Registering image #54 (47)\n",
      "I20250512 22:32:20.651201 769273 incremental_pipeline.cc:408] => Image sees 553 / 1310 points\n",
      "W20250512 22:32:20.739324 769273 incremental_pipeline.cc:55] Could not read image frame_0052.png at path data/xe_F1_khan_60_test2/images_test.\n",
      "I20250512 22:32:20.739347 769273 incremental_pipeline.cc:405] Registering image #53 (48)\n",
      "I20250512 22:32:20.739353 769273 incremental_pipeline.cc:408] => Image sees 683 / 1380 points\n",
      "I20250512 22:32:20.822052 769273 incremental_pipeline.cc:42] Retriangulation and Global bundle adjustment\n",
      "W20250512 22:32:21.057423 769273 incremental_pipeline.cc:55] Could not read image frame_0051.png at path data/xe_F1_khan_60_test2/images_test.\n",
      "I20250512 22:32:21.057448 769273 incremental_pipeline.cc:405] Registering image #52 (49)\n",
      "I20250512 22:32:21.057453 769273 incremental_pipeline.cc:408] => Image sees 757 / 1306 points\n",
      "W20250512 22:32:21.146508 769273 incremental_pipeline.cc:55] Could not read image frame_0050.png at path data/xe_F1_khan_60_test2/images_test.\n",
      "I20250512 22:32:21.146534 769273 incremental_pipeline.cc:405] Registering image #51 (50)\n",
      "I20250512 22:32:21.146539 769273 incremental_pipeline.cc:408] => Image sees 681 / 1154 points\n",
      "W20250512 22:32:21.234464 769273 incremental_pipeline.cc:55] Could not read image frame_0049.png at path data/xe_F1_khan_60_test2/images_test.\n",
      "I20250512 22:32:21.234486 769273 incremental_pipeline.cc:405] Registering image #2 (51)\n",
      "I20250512 22:32:21.234490 769273 incremental_pipeline.cc:408] => Image sees 541 / 928 points\n",
      "I20250512 22:32:21.325323 769273 incremental_pipeline.cc:405] Registering image #3 (52)\n",
      "I20250512 22:32:21.325342 769273 incremental_pipeline.cc:408] => Image sees 568 / 878 points\n",
      "I20250512 22:32:21.415848 769273 incremental_pipeline.cc:405] Registering image #47 (53)\n",
      "I20250512 22:32:21.415864 769273 incremental_pipeline.cc:408] => Image sees 389 / 847 points\n",
      "I20250512 22:32:21.483048 769273 incremental_pipeline.cc:42] Retriangulation and Global bundle adjustment\n",
      "W20250512 22:32:22.198653 769273 incremental_pipeline.cc:55] Could not read image frame_0041.png at path data/xe_F1_khan_60_test2/images_test.\n",
      "I20250512 22:32:22.198678 769273 incremental_pipeline.cc:405] Registering image #43 (54)\n",
      "I20250512 22:32:22.198683 769273 incremental_pipeline.cc:408] => Image sees 433 / 1068 points\n",
      "W20250512 22:32:22.262120 769273 incremental_pipeline.cc:55] Could not read image frame_0042.png at path data/xe_F1_khan_60_test2/images_test.\n",
      "I20250512 22:32:22.262145 769273 incremental_pipeline.cc:405] Registering image #48 (55)\n",
      "I20250512 22:32:22.262151 769273 incremental_pipeline.cc:408] => Image sees 512 / 1091 points\n",
      "W20250512 22:32:22.325325 769273 incremental_pipeline.cc:55] Could not read image frame_0043.png at path data/xe_F1_khan_60_test2/images_test.\n",
      "I20250512 22:32:22.325349 769273 incremental_pipeline.cc:405] Registering image #44 (56)\n",
      "I20250512 22:32:22.325354 769273 incremental_pipeline.cc:408] => Image sees 573 / 999 points\n",
      "W20250512 22:32:22.390089 769273 incremental_pipeline.cc:55] Could not read image frame_0044.png at path data/xe_F1_khan_60_test2/images_test.\n",
      "I20250512 22:32:22.390112 769273 incremental_pipeline.cc:405] Registering image #49 (57)\n",
      "I20250512 22:32:22.390116 769273 incremental_pipeline.cc:408] => Image sees 552 / 909 points\n",
      "W20250512 22:32:22.455627 769273 incremental_pipeline.cc:55] Could not read image frame_0045.png at path data/xe_F1_khan_60_test2/images_test.\n",
      "I20250512 22:32:22.455647 769273 incremental_pipeline.cc:405] Registering image #46 (58)\n",
      "I20250512 22:32:22.455652 769273 incremental_pipeline.cc:408] => Image sees 560 / 826 points\n",
      "W20250512 22:32:22.523167 769273 incremental_pipeline.cc:55] Could not read image frame_0046.png at path data/xe_F1_khan_60_test2/images_test.\n",
      "I20250512 22:32:22.523190 769273 incremental_pipeline.cc:405] Registering image #50 (59)\n",
      "I20250512 22:32:22.523195 769273 incremental_pipeline.cc:408] => Image sees 544 / 706 points\n",
      "I20250512 22:32:22.587235 769273 incremental_pipeline.cc:42] Retriangulation and Global bundle adjustment\n",
      "W20250512 22:32:22.969135 769273 incremental_pipeline.cc:55] Could not read image frame_0047.png at path data/xe_F1_khan_60_test2/images_test.\n",
      "I20250512 22:32:22.969161 769273 incremental_pipeline.cc:405] Registering image #58 (60)\n",
      "I20250512 22:32:22.969166 769273 incremental_pipeline.cc:408] => Image sees 1303 / 1804 points\n",
      "W20250512 22:32:23.095292 769273 incremental_pipeline.cc:55] Could not read image frame_0057.png at path data/xe_F1_khan_60_test2/images_test.\n",
      "I20250512 22:32:23.095314 769273 incremental_pipeline.cc:42] Retriangulation and Global bundle adjustment\n",
      "I20250512 22:32:23.504899 769273 incremental_pipeline.cc:554] Keeping successful reconstruction\n",
      "I20250512 22:32:23.513296 769273 timer.cc:91] Elapsed time: 0.173 [minutes]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "TEMP_database_path = f\"{DATASET_PATH}/database.db\"\n",
    "TEMP_image_path = f\"{DATASET_PATH}/images_test\"\n",
    "TEMP_out_path = f\"{DATASET_PATH}/sparse\"\n",
    "os.makedirs(TEMP_out_path, exist_ok=True)\n",
    "assert os.path.exists(TEMP_database_path), f\"Database path {TEMP_database_path} does not exist.\"\n",
    "assert os.path.exists(TEMP_image_path), f\"Image path {TEMP_image_path} does not exist.\"\n",
    "assert os.path.exists(TEMP_out_path), f\"Output path {TEMP_out_path} does not exist.\"\n",
    "!colmap mapper \\\n",
    "    --database_path $TEMP_database_path \\\n",
    "    --image_path $TEMP_image_path \\\n",
    "    --out $TEMP_out_path \\\n",
    "    --Mapper.min_num_matches 15 \\\n",
    "    --Mapper.ba_global_max_num_iterations 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert .bin to .txt\n",
    "TEMP_out_path = f\"{DATASET_PATH}/sparse/0\"\n",
    "!colmap model_converter \\\n",
    "    --input_path $TEMP_out_path \\\n",
    "    --output_path $TEMP_out_path \\\n",
    "    --output_type TXT\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DENSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TEMP_image_path = f\"{DATASET_PATH}/images\"\n",
    "# TEMP_input_path = f\"{DATASET_PATH}/sparse/0\"\n",
    "# TEMP_output_path = f\"{DATASET_PATH}/dense\"\n",
    "# os.makedirs(TEMP_output_path, exist_ok=True)\n",
    "# assert os.path.exists(TEMP_image_path), f\"Image path {TEMP_image_path} does not exist.\"\n",
    "# assert os.path.exists(TEMP_input_path), f\"Input path {TEMP_input_path} does not exist.\"\n",
    "# assert os.path.exists(TEMP_output_path), f\"Output path {TEMP_output_path} does not exist.\"\n",
    "\n",
    "# !colmap image_undistorter \\\n",
    "#     --image_path $TEMP_image_path \\\n",
    "#     --input_path $TEMP_input_path \\\n",
    "#     --output_path $TEMP_output_path \\\n",
    "#     --output_type COLMAP \\\n",
    "#     --max_image_size 2000 \\\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Patch match stereo -> dense -> .ply"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "E20250410 09:18:47.969971 6560374 mvs.cc:80] Dense stereo reconstruction requires CUDA, which is not available on your system.\n"
     ]
    }
   ],
   "source": [
    "# ## Cn GPU\n",
    "\n",
    "# TEMP_workspace_path = f\"{DATASET_PATH}/dense\"\n",
    "# assert os.path.exists(TEMP_workspace_path), f\"Workspace path {TEMP_workspace_path} does not exist.\"\n",
    "\n",
    "# !colmap patch_match_stereo \\\n",
    "#     --workspace_path $TEMP_workspace_path \\\n",
    "#     --workspace_format COLMAP \\\n",
    "#     --PatchMatchStereo.geom_consistency true \\\n",
    "#     --PatchMatchStereo.use_gpu 1 \\\n",
    "\n",
    "# TEMP_workspace_path = f\"{DATASET_PATH}/dense\"\n",
    "# assert os.path.exists(TEMP_workspace_path), f\"Workspace path {TEMP_workspace_path} does not exist.\"\n",
    "# TEMP_output_path = f\"{DATASET_PATH}/fused.ply\"\n",
    "\n",
    "# !colmap stereo_fusion \\\n",
    "#     --workspace_path $DATASET_PATH/dense \\\n",
    "#     --workspace_format COLMAP \\\n",
    "#     --input_type geometric \\\n",
    "#     --output_path $DATASET_PATH/dense/fused.ply"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stereo fusion -> .ply"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEMP_input_path = f\"{DATASET_PATH}/sparse/0\"\n",
    "TEMP_output_path = f\"{DATASET_PATH}/output.ply\"\n",
    "assert os.path.exists(TEMP_input_path), f\"Input path {TEMP_input_path} does not exist.\"\n",
    "\n",
    "!colmap model_converter \\\n",
    "    --input_path $TEMP_input_path \\\n",
    "    --output_path $TEMP_output_path \\\n",
    "    --output_type PLY\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image names in the dataset: ['frame_0000.png', 'frame_0040.png', 'frame_0048.png', 'frame_0016.png', 'frame_0032.png', 'frame_0008.png', 'frame_0024.png', 'frame_0056.png', 'frame_0003.png', 'frame_0002.png', 'frame_0004.png', 'frame_0005.png', 'frame_0001.png', 'frame_0010.png', 'frame_0007.png', 'frame_0014.png', 'frame_0011.png', 'frame_0012.png', 'frame_0013.png', 'frame_0009.png', 'frame_0006.png', 'frame_0015.png', 'frame_0017.png', 'frame_0018.png', 'frame_0019.png', 'frame_0020.png', 'frame_0029.png', 'frame_0028.png', 'frame_0021.png', 'frame_0022.png', 'frame_0026.png', 'frame_0025.png', 'frame_0030.png', 'frame_0023.png', 'frame_0027.png', 'frame_0031.png', 'frame_0033.png', 'frame_0035.png', 'frame_0034.png', 'frame_0036.png', 'frame_0038.png', 'frame_0039.png', 'frame_0042.png', 'frame_0044.png', 'frame_0037.png', 'frame_0046.png', 'frame_0041.png', 'frame_0043.png', 'frame_0045.png', 'frame_0047.png', 'frame_0049.png', 'frame_0050.png', 'frame_0051.png', 'frame_0052.png', 'frame_0053.png', 'frame_0054.png', 'frame_0055.png', 'frame_0057.png', 'frame_0058.png', 'frame_0059.png']\n",
      "Test image names: ['frame_0000.png', 'frame_0016.png', 'frame_0048.png', 'frame_0056.png', 'frame_0040.png', 'frame_0008.png', 'frame_0032.png', 'frame_0024.png']\n",
      "Test image IDs: [1, 2, 3, 4, 5, 6, 7, 8]\n"
     ]
    }
   ],
   "source": [
    "## split train test from cameras.bin and images.bin and points3d.bin and database.db\n",
    "import os\n",
    "from colmap.scripts.python.read_write_model import read_cameras_binary, read_images_binary, read_points3D_binary\n",
    "from colmap.scripts.python.read_write_model import write_cameras_binary, write_images_binary, write_points3D_binary\n",
    "\n",
    "\n",
    "def split_test(dataset_path, llffhold=8):\n",
    "    \"\"\"\n",
    "    Split the dataset into train and test sets.\n",
    "    \n",
    "    Parameters:\n",
    "        dataset_path (str): Path to the dataset directory.\n",
    "        train_ratio (float): Ratio of training data (default is 0.8).\n",
    "    \"\"\"\n",
    "    # Load the database\n",
    "    database_path = os.path.join(dataset_path, 'database.db')\n",
    "    assert os.path.exists(database_path), f\"Database path {database_path} does not exist.\"\n",
    "    \n",
    "    # Load the cameras, images, and points3D\n",
    "    cameras_path = os.path.join(dataset_path, 'sparse/0/cameras.bin')\n",
    "    images_path = os.path.join(dataset_path, 'sparse/0/images.bin')\n",
    "    points3d_path = os.path.join(dataset_path, 'sparse/0/points3D.bin')\n",
    "    \n",
    "    assert os.path.exists(cameras_path), f\"Cameras path {cameras_path} does not exist.\"\n",
    "    assert os.path.exists(images_path), f\"Images path {images_path} does not exist.\"\n",
    "    assert os.path.exists(points3d_path), f\"Points3D path {points3d_path} does not exist.\"\n",
    "    \n",
    "    # Load the cameras\n",
    "    cameras = read_cameras_binary(cameras_path)\n",
    "    assert cameras is not None, \"Failed to load cameras.\"\n",
    "    # Load the images\n",
    "    images = read_images_binary(images_path)\n",
    "    assert images is not None, \"Failed to load images.\"\n",
    "    # Load the points3D\n",
    "    points3D = read_points3D_binary(points3d_path)\n",
    "    assert points3D is not None, \"Failed to load points3D.\"\n",
    "    # Split the images into train and test sets; if image_id % llffhold == 0, it's in the test set\n",
    "    test_img_dir = os.path.join(dataset_path, 'images_test')\n",
    "    test_img_name_list = os.listdir(test_img_dir)\n",
    "    image_ids = list(images.keys())\n",
    "\n",
    "    a_list = [images[image_id].name for image_id in image_ids]\n",
    "    print(\"Image names in the dataset:\", a_list)\n",
    "    print(\"Test image names:\", test_img_name_list)\n",
    "    test_image_ids = [image_id for image_id in image_ids if images[image_id].name in test_img_name_list]\n",
    "\n",
    "    # image_ids = list(images.keys())\n",
    "    # image_ids.sort()\n",
    "    # test_image_ids = []\n",
    "    # for i, image_id in enumerate(image_ids):\n",
    "    #     print(\"image :\", images[image_id])\n",
    "    #     if i % llffhold == 0:\n",
    "    #         test_image_ids.append(image_id)\n",
    "    print(\"Test image IDs:\", test_image_ids)\n",
    "    \n",
    "    # Create directories for train and test sets\n",
    "    test_dir = os.path.join(dataset_path, 'test')\n",
    "    os.makedirs(test_dir, exist_ok=True)\n",
    "    # Save the train and test sets\n",
    "    test_cameras_path = os.path.join(test_dir, 'cameras.bin')\n",
    "    test_images_path = os.path.join(test_dir, 'images.bin')\n",
    "    test_points3D_path = os.path.join(test_dir, 'points3D.bin')\n",
    "    # Save the cameras\n",
    "    write_cameras_binary(cameras, test_cameras_path)\n",
    "    # Save the images\n",
    "    test_images = {image_id: images[image_id] for image_id in test_image_ids}\n",
    "    write_images_binary(test_images, test_images_path)\n",
    "    # Save the points3D\n",
    "    test_points3D = {point3D_id: points3D[point3D_id] for point3D_id in points3D.keys() if point3D_id in test_image_ids}\n",
    "    write_points3D_binary(test_points3D, test_points3D_path)\n",
    "\n",
    "split_test(DATASET_PATH, llffhold=8)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cal metrics from mesh.obj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Loading cameras and images...\n",
      " Loading mesh...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Volumes/Projects/opt/anaconda3/lib/python3.12/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/Volumes/Projects/opt/anaconda3/lib/python3.12/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=AlexNet_Weights.IMAGENET1K_V1`. You can also use `weights=AlexNet_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "point3D.bin :  /Volumes/Projects/3drn/data/xe_F1_khan_60_test2/test/points3D.bin\n",
      "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
      "Loading model from: /Volumes/Projects/opt/anaconda3/lib/python3.12/site-packages/lpips/weights/v0.1/alex.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Rendering and comparing:   0%|          | 0/8 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fx: 1146.4364194057184  - fy: 1146.4364194057184  - cx: 640.0  - cy: 360.0\n",
      " Intrinsic matrix K:\n",
      " [[1.14643642e+03 0.00000000e+00 6.40000000e+02]\n",
      " [0.00000000e+00 1.14643642e+03 3.60000000e+02]\n",
      " [0.00000000e+00 0.00000000e+00 1.00000000e+00]]\n",
      "GT image shape: (720, 1280, 3)\n",
      "Predicted image shape: (720, 1280, 3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Rendering and comparing:  12%|        | 1/8 [00:00<00:03,  2.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "frame_0000.png: PSNR=18.62, SSIM=0.368, LPIPS=0.292\n",
      "fx: 1134.515868992312  - fy: 1134.515868992312  - cx: 640.0  - cy: 360.0\n",
      " Intrinsic matrix K:\n",
      " [[1.13451587e+03 0.00000000e+00 6.40000000e+02]\n",
      " [0.00000000e+00 1.13451587e+03 3.60000000e+02]\n",
      " [0.00000000e+00 0.00000000e+00 1.00000000e+00]]\n",
      "GT image shape: (720, 1280, 3)\n",
      "Predicted image shape: (720, 1280, 3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Rendering and comparing:  25%|       | 2/8 [00:00<00:02,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "frame_0040.png: PSNR=21.94, SSIM=0.587, LPIPS=0.194\n",
      "fx: 1151.5021007990495  - fy: 1151.5021007990495  - cx: 640.0  - cy: 360.0\n",
      " Intrinsic matrix K:\n",
      " [[1.1515021e+03 0.0000000e+00 6.4000000e+02]\n",
      " [0.0000000e+00 1.1515021e+03 3.6000000e+02]\n",
      " [0.0000000e+00 0.0000000e+00 1.0000000e+00]]\n",
      "GT image shape: (720, 1280, 3)\n",
      "Predicted image shape: (720, 1280, 3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Rendering and comparing:  38%|      | 3/8 [00:01<00:02,  2.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "frame_0048.png: PSNR=22.21, SSIM=0.687, LPIPS=0.203\n",
      "fx: 1142.4677776724109  - fy: 1142.4677776724109  - cx: 640.0  - cy: 360.0\n",
      " Intrinsic matrix K:\n",
      " [[1.14246778e+03 0.00000000e+00 6.40000000e+02]\n",
      " [0.00000000e+00 1.14246778e+03 3.60000000e+02]\n",
      " [0.00000000e+00 0.00000000e+00 1.00000000e+00]]\n",
      "GT image shape: (720, 1280, 3)\n",
      "Predicted image shape: (720, 1280, 3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Rendering and comparing:  50%|     | 4/8 [00:01<00:01,  2.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "frame_0016.png: PSNR=20.17, SSIM=0.623, LPIPS=0.248\n",
      "fx: 1131.1081880188333  - fy: 1131.1081880188333  - cx: 640.0  - cy: 360.0\n",
      " Intrinsic matrix K:\n",
      " [[1.13110819e+03 0.00000000e+00 6.40000000e+02]\n",
      " [0.00000000e+00 1.13110819e+03 3.60000000e+02]\n",
      " [0.00000000e+00 0.00000000e+00 1.00000000e+00]]\n",
      "GT image shape: (720, 1280, 3)\n",
      "Predicted image shape: (720, 1280, 3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Rendering and comparing:  62%|   | 5/8 [00:02<00:01,  2.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "frame_0032.png: PSNR=20.52, SSIM=0.532, LPIPS=0.225\n",
      "fx: 1158.615018164056  - fy: 1158.615018164056  - cx: 640.0  - cy: 360.0\n",
      " Intrinsic matrix K:\n",
      " [[1.15861502e+03 0.00000000e+00 6.40000000e+02]\n",
      " [0.00000000e+00 1.15861502e+03 3.60000000e+02]\n",
      " [0.00000000e+00 0.00000000e+00 1.00000000e+00]]\n",
      "GT image shape: (720, 1280, 3)\n",
      "Predicted image shape: (720, 1280, 3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Rendering and comparing:  75%|  | 6/8 [00:02<00:00,  2.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "frame_0008.png: PSNR=19.42, SSIM=0.545, LPIPS=0.265\n",
      "fx: 1157.1897566325913  - fy: 1157.1897566325913  - cx: 640.0  - cy: 360.0\n",
      " Intrinsic matrix K:\n",
      " [[1.15718976e+03 0.00000000e+00 6.40000000e+02]\n",
      " [0.00000000e+00 1.15718976e+03 3.60000000e+02]\n",
      " [0.00000000e+00 0.00000000e+00 1.00000000e+00]]\n",
      "GT image shape: (720, 1280, 3)\n",
      "Predicted image shape: (720, 1280, 3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Rendering and comparing:  88%| | 7/8 [00:03<00:00,  2.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "frame_0024.png: PSNR=20.24, SSIM=0.566, LPIPS=0.256\n",
      "fx: 1149.9598159342056  - fy: 1149.9598159342056  - cx: 640.0  - cy: 360.0\n",
      " Intrinsic matrix K:\n",
      " [[1.14995982e+03 0.00000000e+00 6.40000000e+02]\n",
      " [0.00000000e+00 1.14995982e+03 3.60000000e+02]\n",
      " [0.00000000e+00 0.00000000e+00 1.00000000e+00]]\n",
      "GT image shape: (720, 1280, 3)\n",
      "Predicted image shape: (720, 1280, 3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Rendering and comparing: 100%|| 8/8 [00:03<00:00,  2.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "frame_0056.png: PSNR=20.19, SSIM=0.535, LPIPS=0.219\n",
      "\n",
      " Done! Average metrics:\n",
      "PSNR: 20.41\n",
      "SSIM: 0.555\n",
      "LPIPS: 0.238\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import torch\n",
    "import lpips\n",
    "import numpy as np\n",
    "import open3d as o3d\n",
    "import pyrender\n",
    "import trimesh\n",
    "from tqdm import tqdm\n",
    "from skimage.metrics import structural_similarity as compare_ssim\n",
    "from skimage.metrics import peak_signal_noise_ratio as compare_psnr\n",
    "from colmap.scripts.python.read_write_model import read_cameras_binary, read_images_binary\n",
    "\n",
    "# =======================\n",
    "# Load Camera Intrinsics\n",
    "# =======================\n",
    "# def load_intrinsics(camera):\n",
    "#     print('camera info: ', camera)\n",
    "#     fx, fy, cx, cy = camera.params[:4]\n",
    "#     width, height = int(camera.width), int(camera.height)\n",
    "#     K = np.array([[fx, 0, cx],\n",
    "#                   [0, fy, cy],\n",
    "#                   [0,  0,  1]])\n",
    "#     return K, width, height\n",
    "def load_intrinsics(camera):\n",
    "    model = camera.model\n",
    "\n",
    "    if model in ['SIMPLE_PINHOLE', 'SIMPLE_RADIAL']:\n",
    "        f, cx, cy = camera.params[:3]\n",
    "        fx = fy = f\n",
    "        if cy < 1e-2:\n",
    "            print(\" Detected invalid cy ( 0), overriding to image center.\")\n",
    "            cy = camera.height / 2\n",
    "    elif model == 'PINHOLE':\n",
    "        fx, fy, cx, cy = camera.params[:4]\n",
    "    else:\n",
    "        raise ValueError(f\" Unsupported camera model: {model}\")\n",
    "\n",
    "    K = np.array([[fx, 0, cx],\n",
    "                  [0, fy, cy],\n",
    "                  [0,  0,  1]])\n",
    "    width, height = int(camera.width), int(camera.height)\n",
    "\n",
    "    print(f\"fx: {fx}  - fy: {fy}  - cx: {cx}  - cy: {cy}\")\n",
    "    if abs(cx - width / 2) > width * 0.1 or abs(cy - height / 2) > height * 0.1:\n",
    "        print(\"  Warning: cx, cy lch xa trung tm nh. Kim tra li ni ti COLMAP hoc nh  resize.\")\n",
    "\n",
    "    print(\" Intrinsic matrix K:\\n\", K)\n",
    "    return K, width, height\n",
    "# =======================\n",
    "# Load Camera Extrinsics\n",
    "# =======================\n",
    "def load_extrinsics(image):\n",
    "    R = image.qvec2rotmat()\n",
    "    t = image.tvec.reshape(3, 1)\n",
    "    # Colmap: world to camera => cn nghch o  camera to world\n",
    "    Rt = np.eye(4)\n",
    "    Rt[:3, :3] = R\n",
    "    Rt[:3, 3] = t[:, 0]\n",
    "    return np.linalg.inv(Rt)\n",
    "\n",
    "# =======================\n",
    "# Render Image\n",
    "# =======================\n",
    "def render_scene(mesh, K, width, height, pose):\n",
    "    scene = pyrender.Scene(bg_color=[0, 0, 0, 0], ambient_light=[0.3, 0.3, 0.3])\n",
    "    scene.add(mesh)\n",
    "\n",
    "    camera = pyrender.IntrinsicsCamera(\n",
    "        fx=K[0, 0], fy=K[1, 1],\n",
    "        cx=K[0, 2], cy=K[1, 2],\n",
    "        znear=0.1, zfar=100.0\n",
    "    )\n",
    "\n",
    "    # Convert Colmap to OpenGL camera frame\n",
    "    flip_transform = np.eye(4)\n",
    "    flip_transform[1, 1] = -1\n",
    "    flip_transform[2, 2] = -1\n",
    "    pose = pose @ flip_transform\n",
    "\n",
    "    scene.add(camera, pose=pose)\n",
    "\n",
    "    # light = pyrender.DirectionalLight(color=np.ones(3), intensity=2.0)\n",
    "    # scene.add(light, pose=pose)\n",
    "\n",
    "    renderer = pyrender.OffscreenRenderer(viewport_width=width, viewport_height=height)\n",
    "    color, depth = renderer.render(scene, flags=pyrender.RenderFlags.FLAT | pyrender.RenderFlags.SKIP_CULL_FACES)\n",
    "\n",
    "    renderer.delete()\n",
    "    return color\n",
    "\n",
    "# =======================\n",
    "# Compute Metrics\n",
    "# =======================\n",
    "def compute_metrics(gt_image, pred_image, loss_fn_alex):\n",
    "    # Resize pred_image if needed\n",
    "    if gt_image.shape != pred_image.shape:\n",
    "        pred_image = cv2.resize(pred_image, (gt_image.shape[1], gt_image.shape[0]))\n",
    "\n",
    "    # Convert to float32\n",
    "    gt_float = gt_image.astype(np.float32) / 255.0\n",
    "    pred_float = pred_image.astype(np.float32) / 255.0\n",
    "\n",
    "    # PSNR\n",
    "    psnr = compare_psnr(gt_float, pred_float, data_range=1.0)\n",
    "\n",
    "    # SSIM\n",
    "    print(f\"GT image shape: {gt_image.shape}\")\n",
    "    print(f\"Predicted image shape: {pred_image.shape}\")\n",
    "    # ssim = compare_ssim(gt_float, pred_float, multichannel=True, data_range=1.0)\n",
    "    ssim = compare_ssim(gt_float, pred_float, multichannel=True, data_range=1.0, win_size=3)\n",
    "    \n",
    "    # LPIPS\n",
    "    gt_tensor = torch.tensor(gt_float).permute(2, 0, 1).unsqueeze(0).float()\n",
    "    pred_tensor = torch.tensor(pred_float).permute(2, 0, 1).unsqueeze(0).float()\n",
    "    lpips_value = loss_fn_alex(gt_tensor, pred_tensor).item()\n",
    "    # print(lpips_value)\n",
    "    if lpips_value=='nan':\n",
    "        lpips_value = 1\n",
    "    return psnr, ssim, lpips_value\n",
    "\n",
    "# =======================\n",
    "# Main\n",
    "# =======================\n",
    "def main():\n",
    "    # sparse_dir = \"/Volumes/Projects/3drn/data/new_project_xeF1_100/sparse/0\"\n",
    "    sparse_dir = \"/Volumes/Projects/3drn/data/xe_F1_khan_60_test2/test\"\n",
    "    ply_file = \"/Volumes/Projects/3drn/data/new_project_xeF1_100/dense/0/xe_F1_100_chualoc.obj\"\n",
    "    images_dir = \"/Volumes/Projects/3drn/data/xe_F1_khan_60_test2/images_test\"\n",
    "    output_dir= \"/Volumes/Projects/3drn/data/xe_F1_khan_60_test2/rendered_images_70_May12\"\n",
    "\n",
    "    # data_dir = \"data\"\n",
    "    # images_dir = os.path.join(data_dir, \"images\")\n",
    "    # sparse_dir = os.path.join(data_dir, \"sparse/0\")\n",
    "    # ply_file = os.path.join(data_dir, \"dense/fused.ply\")\n",
    "    # output_dir = os.path.join(data_dir, \"rendered\")\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "    print(\" Loading cameras and images...\")\n",
    "    cameras = read_cameras_binary(os.path.join(sparse_dir, \"cameras.bin\"))\n",
    "    images = read_images_binary(os.path.join(sparse_dir, \"images.bin\"))\n",
    "\n",
    "\n",
    "    print(\" Loading mesh...\")\n",
    "    # Load the .ply file\n",
    "    mesh = trimesh.load(ply_file)\n",
    "\n",
    "\n",
    "    # Check if the loaded object is a Scene\n",
    "    if isinstance(mesh, trimesh.Scene):\n",
    "        # Extract the first geometry from the Scene\n",
    "        mesh = mesh.dump(concatenate=True)\n",
    "\n",
    "\n",
    "    print('point3D.bin : ', os.path.join(sparse_dir, \"points3D.bin\"))\n",
    "    # mesh = align_mesh_to_sparse(mesh, os.path.join(sparse_dir, \"points3D.bin\"))\n",
    "    # mesh = align_mesh_with_colmap(mesh, os.path.join(sparse_dir, \"points3D.bin\"))\n",
    "\n",
    "    mesh = pyrender.Mesh.from_trimesh(mesh)\n",
    "    \n",
    "\n",
    "    # # Assume single camera\n",
    "    # camera = list(cameras.values())[0]\n",
    "    # # camera = list(cameras.values())[3]\n",
    "    # K, width, height = load_intrinsics(camera)\n",
    "\n",
    "    loss_fn_alex = lpips.LPIPS(net='alex')\n",
    "\n",
    "    psnr_list, ssim_list, lpips_list = [], [], []\n",
    "\n",
    "    for image_name, image in tqdm(images.items(), desc=\"Rendering and comparing\"):\n",
    "        pose = load_extrinsics(image)\n",
    "\n",
    "        camera = cameras[image.camera_id]\n",
    "        K, width, height = load_intrinsics(camera)\n",
    "\n",
    "        # Render\n",
    "        color = render_scene(mesh, K, width, height, pose)\n",
    "        output_path = os.path.join(output_dir, os.path.splitext(image.name)[0] + \".png\")\n",
    "        cv2.imwrite(output_path, cv2.cvtColor(color, cv2.COLOR_RGB2BGR))\n",
    "\n",
    "        # Load ground truth\n",
    "        gt_path = os.path.join(images_dir, image.name)\n",
    "        if not os.path.exists(gt_path):\n",
    "            print(f\" Ground truth image {gt_path} not found, skipping.\")\n",
    "            continue\n",
    "        gt_image = cv2.imread(gt_path)\n",
    "        pred_image = color\n",
    "\n",
    "        # Compute metrics\n",
    "        psnr, ssim, lpips_value = compute_metrics(gt_image, pred_image, loss_fn_alex)\n",
    "        psnr_list.append(psnr)\n",
    "        ssim_list.append(ssim)\n",
    "        lpips_list.append(lpips_value)\n",
    "\n",
    "        print(f\"{image.name}: PSNR={psnr:.2f}, SSIM={ssim:.3f}, LPIPS={lpips_value:.3f}\")\n",
    "\n",
    "    print(\"\\n Done! Average metrics:\")\n",
    "    print(f\"PSNR: {np.mean(psnr_list):.2f}\")\n",
    "    print(f\"SSIM: {np.mean(ssim_list):.3f}\")\n",
    "    print(f\"LPIPS: {np.mean(lpips_list):.3f}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[WARNING] Bad average root: nan\n",
      "\t(-0.215303 -0.220932) (0.457721)\n",
      "[WARNING] Bad average root: nan\n",
      "\t(-0.274327 -0.215303) (0.457721)\n",
      "[ERROR] Failed to close loop [8: 194 154 78] | (492401): 11118271948396616\n"
     ]
    }
   ],
   "source": [
    "!colmap poisson_mesher \\\n",
    "    --input_path /Volumes/Projects/3drn/data/new_project_xeF1_100/dense/0/fused.ply \\\n",
    "    --output_path /Volumes/Projects/3drn/data/new_project_xeF1_100/dense/0/mesh.ply \\\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import open3d as o3d\n",
    "\n",
    "# path_mesh = '/Volumes/Projects/3drn/data/new_project_xeF1_100/dense/0/fused.ply'\n",
    "# mesh = o3d.io.read_point_cloud(path_mesh)\n",
    "# c mesh t file (v d file .obj)\n",
    "path_mesh = '/Volumes/Projects/3drn/data/new_project_xeF1_100/dense/0/xe_F1_100_chualoc.obj'\n",
    "mesh = o3d.io.read_triangle_mesh(path_mesh)\n",
    "\n",
    "# Kim tra xem mesh c hp l khng\n",
    "if not mesh.is_empty():\n",
    "    print(\"Mesh is loaded successfully.\")\n",
    "else:\n",
    "    print(\"Failed to load mesh.\")\n",
    "\n",
    "# Hin th mesh\n",
    "o3d.visualization.draw_geometries([mesh])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import open3d as o3d\n",
    "from colmap.scripts.python.read_write_model import read_images_binary, read_cameras_binary\n",
    "\n",
    "def load_camera_frustum(K, width, height, scale=0.2):\n",
    "    fx, fy, cx, cy = K[0,0], K[1,1], K[0,2], K[1,2]\n",
    "\n",
    "    # Camera frustum points in camera space\n",
    "    points = [\n",
    "        [0, 0, 0],  # camera center\n",
    "        [(0 - cx) / fx, (0 - cy) / fy, 1.0],\n",
    "        [(width - cx) / fx, (0 - cy) / fy, 1.0],\n",
    "        [(width - cx) / fx, (height - cy) / fy, 1.0],\n",
    "        [(0 - cx) / fx, (height - cy) / fy, 1.0],\n",
    "    ]\n",
    "    points = np.array(points) * scale\n",
    "\n",
    "    lines = [\n",
    "        [0, 1], [0, 2], [0, 3], [0, 4],\n",
    "        [1, 2], [2, 3], [3, 4], [4, 1],\n",
    "    ]\n",
    "\n",
    "    colors = [[1, 0, 0] for _ in lines]  # red frustum\n",
    "    line_set = o3d.geometry.LineSet(\n",
    "        points=o3d.utility.Vector3dVector(points),\n",
    "        lines=o3d.utility.Vector2iVector(lines),\n",
    "    )\n",
    "    line_set.colors = o3d.utility.Vector3dVector(colors)\n",
    "    return line_set\n",
    "\n",
    "def create_camera_geometry(pose, K, width, height, scale=0.2):\n",
    "    frustum = load_camera_frustum(K, width, height, scale)\n",
    "    frustum.transform(pose)\n",
    "    return frustum\n",
    "\n",
    "def main():\n",
    "    # === PATHS ===\n",
    "    sparse_dir = \"/Volumes/Projects/3drn/data/xe_F1_khan_60_test2/test\"\n",
    "    mesh_path = \"/Volumes/Projects/3drn/data/new_project_xeF1_100/dense/0/xe_F1_100_chualoc.obj\"\n",
    "\n",
    "    # === LOAD COLMAP ===\n",
    "    cameras = read_cameras_binary(os.path.join(sparse_dir, \"cameras.bin\"))\n",
    "    images = read_images_binary(os.path.join(sparse_dir, \"images.bin\"))\n",
    "    camera = list(cameras.values())[0]\n",
    "    fx, fy, cx, cy = camera.params[:4]\n",
    "    width, height = int(camera.width), int(camera.height)\n",
    "    K = np.array([[fx, 0, cx],\n",
    "                  [0, fy, cy],\n",
    "                  [0,  0,  1]])\n",
    "\n",
    "    # === LOAD MESH ===\n",
    "    mesh = o3d.io.read_triangle_mesh(mesh_path)\n",
    "    mesh.compute_vertex_normals()\n",
    "\n",
    "    # === CREATE CAMERA GEOMETRY ===\n",
    "    geometries = [mesh]\n",
    "    for image in images.values():\n",
    "        R = image.qvec2rotmat()\n",
    "        t = image.tvec.reshape(3, 1)\n",
    "        Rt = np.eye(4)\n",
    "        Rt[:3, :3] = R\n",
    "        Rt[:3, 3] = t[:, 0]\n",
    "\n",
    "        cam_to_world = np.linalg.inv(Rt)\n",
    "\n",
    "        # Flip to Open3D (z forward, y up)\n",
    "        flip_transform = np.eye(4)\n",
    "        flip_transform[1, 1] = -1\n",
    "        flip_transform[2, 2] = -1\n",
    "        cam_to_world = cam_to_world @ flip_transform\n",
    "\n",
    "        frustum = create_camera_geometry(cam_to_world, K, width, height, scale=0.3)\n",
    "        geometries.append(frustum)\n",
    "\n",
    "    # === VISUALIZE ===\n",
    "    o3d.visualization.draw_geometries(geometries)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import open3d as o3d\n",
    "from colmap.scripts.python.read_write_model import read_cameras_binary, read_images_binary, read_points3D_binary\n",
    "\n",
    "def load_camera_frustum(K, width, height, scale=0.2):\n",
    "    fx, fy, cx, cy = K[0, 0], K[1, 1], K[0, 2], K[1, 2]\n",
    "    points = [\n",
    "        [0, 0, 0],\n",
    "        [(0 - cx) / fx, (0 - cy) / fy, 1.0],\n",
    "        [(width - cx) / fx, (0 - cy) / fy, 1.0],\n",
    "        [(width - cx) / fx, (height - cy) / fy, 1.0],\n",
    "        [(0 - cx) / fx, (height - cy) / fy, 1.0],\n",
    "    ]\n",
    "    points = np.array(points) * scale\n",
    "    lines = [\n",
    "        [0, 1], [0, 2], [0, 3], [0, 4],\n",
    "        [1, 2], [2, 3], [3, 4], [4, 1],\n",
    "    ]\n",
    "    colors = [[1, 0, 0] for _ in lines]  # red lines\n",
    "    frustum = o3d.geometry.LineSet(\n",
    "        points=o3d.utility.Vector3dVector(points),\n",
    "        lines=o3d.utility.Vector2iVector(lines)\n",
    "    )\n",
    "    frustum.colors = o3d.utility.Vector3dVector(colors)\n",
    "    return frustum\n",
    "\n",
    "def create_camera_geometry(pose, K, width, height, scale=0.2):\n",
    "    frustum = load_camera_frustum(K, width, height, scale)\n",
    "    frustum.transform(pose)\n",
    "    return frustum\n",
    "\n",
    "def load_colmap_points(points3d_path):\n",
    "    points3D = read_points3D_binary(points3d_path)\n",
    "    xyz = [p.xyz for p in points3D.values()]\n",
    "    pc = o3d.geometry.PointCloud()\n",
    "    pc.points = o3d.utility.Vector3dVector(np.array(xyz))\n",
    "    pc.paint_uniform_color([0, 1, 0])  # green\n",
    "    return pc\n",
    "\n",
    "def main():\n",
    "    # === PATHS ===\n",
    "    sparse_dir = \"/Volumes/Projects/3drn/data/xe_F1_khan_60_test2/test\"\n",
    "    mesh_path = \"/Volumes/Projects/3drn/data/new_project_xeF1_100/dense/0/xe_F1_100_chualoc.obj\"\n",
    "    points3d_path = os.path.join(sparse_dir, \"points3D.bin\")\n",
    "\n",
    "    # === LOAD COLMAP ===\n",
    "    cameras = read_cameras_binary(os.path.join(sparse_dir, \"cameras.bin\"))\n",
    "    images = read_images_binary(os.path.join(sparse_dir, \"images.bin\"))\n",
    "    camera = list(cameras.values())[0]\n",
    "    fx, fy, cx, cy = camera.params[:4]\n",
    "    width, height = int(camera.width), int(camera.height)\n",
    "    K = np.array([[fx, 0, cx],\n",
    "                  [0, fy, cy],\n",
    "                  [0,  0,  1]])\n",
    "\n",
    "    # === LOAD MESH ===\n",
    "    mesh = o3d.io.read_triangle_mesh(mesh_path)\n",
    "    mesh.compute_vertex_normals()\n",
    "\n",
    "    # === LOAD POINT CLOUD FROM COLMAP ===\n",
    "    points3D = load_colmap_points(points3d_path)\n",
    "\n",
    "    # === COLLECT GEOMETRIES ===\n",
    "    geometries = [mesh, points3D]\n",
    "\n",
    "    for image in images.values():\n",
    "        R = image.qvec2rotmat()\n",
    "        t = image.tvec.reshape(3, 1)\n",
    "        Rt = np.eye(4)\n",
    "        Rt[:3, :3] = R\n",
    "        Rt[:3, 3] = t[:, 0]\n",
    "        cam_to_world = np.linalg.inv(Rt)\n",
    "\n",
    "        # Flip to Open3D (z forward, y up)\n",
    "        flip = np.eye(4)\n",
    "        flip[1, 1] = -1\n",
    "        flip[2, 2] = -1\n",
    "        cam_to_world = cam_to_world @ flip\n",
    "\n",
    "        frustum = create_camera_geometry(cam_to_world, K, width, height, scale=0.3)\n",
    "        geometries.append(frustum)\n",
    "\n",
    "    # === VISUALIZE ALL ===\n",
    "    o3d.visualization.draw_geometries(geometries)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ICP fitness: 0.8108\n",
      "ICP inlier RMSE: 0.5366117087743922\n",
      "ICP transformation:\n",
      " [[ 0.98235532 -0.13663757  0.12770356 -0.42618274]\n",
      " [ 0.15387013  0.97860735 -0.13657102  0.49515893]\n",
      " [-0.10631091  0.15381103  0.98236457 -0.60959315]\n",
      " [ 0.          0.          0.          1.        ]]\n"
     ]
    }
   ],
   "source": [
    "import open3d as o3d\n",
    "import numpy as np\n",
    "from colmap.scripts.python.read_write_model import read_points3D_binary\n",
    "import os\n",
    "\n",
    "def load_colmap_points(points3d_path):\n",
    "    points3D = read_points3D_binary(points3d_path)\n",
    "    xyz = [p.xyz for p in points3D.values()]\n",
    "    pc = o3d.geometry.PointCloud()\n",
    "    pc.points = o3d.utility.Vector3dVector(np.array(xyz))\n",
    "    pc.paint_uniform_color([0, 1, 0])  # green\n",
    "    return pc\n",
    "\n",
    "def align_mesh_with_colmap(mesh_path, points3d_path):\n",
    "    # Load mesh and convert to point cloud\n",
    "    mesh = o3d.io.read_triangle_mesh(mesh_path)\n",
    "    mesh.compute_vertex_normals()\n",
    "    mesh_pc = mesh.sample_points_uniformly(number_of_points=10000)\n",
    "\n",
    "    # Load COLMAP point cloud\n",
    "    colmap_pc = load_colmap_points(points3d_path)\n",
    "\n",
    "    # ICP Alignment\n",
    "    threshold = 1.0  # distance threshold for ICP\n",
    "    icp_result = o3d.pipelines.registration.registration_icp(\n",
    "        mesh_pc, colmap_pc, threshold,\n",
    "        np.eye(4),\n",
    "        o3d.pipelines.registration.TransformationEstimationPointToPoint()\n",
    "    )\n",
    "\n",
    "    print(\"ICP fitness:\", icp_result.fitness)\n",
    "    print(\"ICP inlier RMSE:\", icp_result.inlier_rmse)\n",
    "    print(\"ICP transformation:\\n\", icp_result.transformation)\n",
    "\n",
    "    # Apply transform to original mesh\n",
    "    mesh.transform(icp_result.transformation)\n",
    "\n",
    "    # Visualize result\n",
    "    mesh_pc_aligned = mesh.sample_points_uniformly(number_of_points=10000)\n",
    "    mesh_pc_aligned.paint_uniform_color([1, 0, 0])  # red\n",
    "    o3d.visualization.draw_geometries([mesh_pc_aligned, colmap_pc])\n",
    "\n",
    "    # Save aligned mesh if needed\n",
    "    # o3d.io.write_triangle_mesh(\"aligned_mesh.ply\", mesh)\n",
    "\n",
    "    return mesh  # aligned mesh\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    mesh_path = \"/Volumes/Projects/3drn/data/new_project_xeF1_100/dense/0/xe_F1_100_chualoc.obj\"\n",
    "    points3d_path = \"/Volumes/Projects/3drn/data/xe_F1_khan_60_test2/test/points3D.bin\"\n",
    "\n",
    "    aligned_mesh = align_mesh_with_colmap(mesh_path, points3d_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Mesh bounding box:\n",
      "   Min: [-1.6425467  0.8469951  1.4751472]\n",
      "   Max: [1.876085  3.3991566 3.9150784]\n",
      "   Center: [0.11676915 2.12307585 2.6951128 ]\n",
      " Camera position: [-0.24831919  2.1123566  -1.97424914]\n",
      "  Forward direction: [0.03051526 0.00633834 0.9995142 ]\n",
      " Up direction: [ 0.05172704 -0.99864995  0.00475363]\n",
      " Camera pose:\n",
      " [[ 0.99819494  0.05172704 -0.03051526 -0.24831919]\n",
      " [ 0.05155685 -0.99864995 -0.00633834  2.1123566 ]\n",
      " [-0.03080192  0.00475363 -0.9995142  -1.97424914]\n",
      " [ 0.          0.          0.          1.        ]]\n",
      " Render saved to render_test.png\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pyrender\n",
    "import trimesh\n",
    "from colmap.scripts.python.read_write_model import read_images_binary, read_cameras_binary\n",
    "\n",
    "def load_intrinsics(camera):\n",
    "    fx, fy, cx, cy = camera.params[:4]\n",
    "    K = np.array([[fx, 0, cx],\n",
    "                  [0, fy, cy],\n",
    "                  [0,  0,  1]])\n",
    "    return K, int(camera.width), int(camera.height)\n",
    "\n",
    "def load_extrinsics(image):\n",
    "    R = image.qvec2rotmat()\n",
    "    t = image.tvec.reshape(3, 1)\n",
    "    Rt = np.eye(4)\n",
    "    Rt[:3, :3] = R\n",
    "    Rt[:3, 3] = t[:, 0]\n",
    "    return np.linalg.inv(Rt)\n",
    "\n",
    "def render_scene(mesh, K, width, height, pose):\n",
    "    scene = pyrender.Scene(bg_color=[0, 0, 0, 0])\n",
    "    scene.add(mesh)\n",
    "\n",
    "    camera = pyrender.IntrinsicsCamera(\n",
    "        fx=K[0, 0], fy=K[1, 1],\n",
    "        cx=K[0, 2], cy=K[1, 2],\n",
    "        znear=0.1, zfar=100.0\n",
    "    )\n",
    "\n",
    "    # Flip from COLMAP to OpenGL\n",
    "    flip_transform = np.eye(4)\n",
    "    flip_transform[1, 1] = -1\n",
    "    flip_transform[2, 2] = -1\n",
    "    pose = pose @ flip_transform\n",
    "\n",
    "    position = pose[:3, 3]\n",
    "    forward = -pose[:3, 2]  # hng nhn (v Z trong OpenGL l backward)\n",
    "    up = pose[:3, 1]\n",
    "    print(\" Camera position:\", position)\n",
    "    print(\"  Forward direction:\", forward)\n",
    "    print(\" Up direction:\", up)\n",
    "\n",
    "\n",
    "    print(\" Camera pose:\\n\", pose)\n",
    "\n",
    "    scene.add(camera, pose=pose)\n",
    "\n",
    "    renderer = pyrender.OffscreenRenderer(viewport_width=width, viewport_height=height)\n",
    "    color, _ = renderer.render(scene)\n",
    "    renderer.delete()\n",
    "    return color\n",
    "\n",
    "def main():\n",
    "    # Paths\n",
    "    sparse_dir = \"/Volumes/Projects/3drn/data/xe_F1_khan_60_test2/test\"\n",
    "    ply_file = \"/Volumes/Projects/3drn/data/new_project_xeF1_100/dense/0/xe_F1_100_chualoc.obj\"\n",
    "    output_image = \"render_test.png\"\n",
    "\n",
    "    # Load COLMAP camera & image\n",
    "    cameras = read_cameras_binary(os.path.join(sparse_dir, \"cameras.bin\"))\n",
    "    images = read_images_binary(os.path.join(sparse_dir, \"images.bin\"))\n",
    "\n",
    "    # Choose 1 camera\n",
    "    image = list(images.values())[0]\n",
    "    camera = cameras[image.camera_id]\n",
    "\n",
    "    K, width, height = load_intrinsics(camera)\n",
    "    pose = load_extrinsics(image)\n",
    "\n",
    "    # Load mesh\n",
    "    mesh = trimesh.load(ply_file)\n",
    "    if isinstance(mesh, trimesh.Scene):\n",
    "        mesh = mesh.dump(concatenate=True)\n",
    "\n",
    "    # Chuyn sang Open3D mesh\n",
    "    mesh_o3d = o3d.geometry.TriangleMesh()\n",
    "    mesh_o3d.vertices = o3d.utility.Vector3dVector(mesh.vertices)\n",
    "    mesh_o3d.triangles = o3d.utility.Vector3iVector(mesh.faces)\n",
    "    mesh_o3d.compute_vertex_normals()\n",
    "\n",
    "    # In bounding box\n",
    "    bbox = mesh_o3d.get_axis_aligned_bounding_box()\n",
    "    print(\" Mesh bounding box:\")\n",
    "    print(\"   Min:\", bbox.get_min_bound())\n",
    "    print(\"   Max:\", bbox.get_max_bound())\n",
    "    print(\"   Center:\", bbox.get_center())\n",
    "\n",
    "    mesh = pyrender.Mesh.from_trimesh(mesh)\n",
    "\n",
    "\n",
    "\n",
    "    # Render one image\n",
    "    color = render_scene(mesh, K, width, height, pose)\n",
    "    cv2.imwrite(output_image, cv2.cvtColor(color, cv2.COLOR_RGB2BGR))\n",
    "    print(\" Render saved to\", output_image)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Mesh bounding box:\n",
      "   Min: [-1.6425467  0.8469951  1.4751472]\n",
      "   Max: [1.876085  3.3991566 3.9150784]\n",
      "   Center: [0.11676915 2.12307585 2.6951128 ]\n",
      " Distance camera  model center: 4.68 units\n",
      " Camera position: [-0.24831919  2.1123566  -1.97424914]\n",
      "  Forward direction: [0.03051526 0.00633834 0.9995142 ]\n",
      " Up direction: [ 0.05172704 -0.99864995  0.00475363]\n",
      " Camera pose:\n",
      " [[ 0.99819494  0.05172704 -0.03051526 -0.24831919]\n",
      " [ 0.05155685 -0.99864995 -0.00633834  2.1123566 ]\n",
      " [-0.03080192  0.00475363 -0.9995142  -1.97424914]\n",
      " [ 0.          0.          0.          1.        ]]\n",
      " Render saved to render_test.png\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pyrender\n",
    "import trimesh\n",
    "import open3d as o3d  #  thm Open3D\n",
    "from colmap.scripts.python.read_write_model import read_images_binary, read_cameras_binary\n",
    "from numpy.linalg import norm\n",
    "\n",
    "\n",
    "def load_intrinsics(camera):\n",
    "    fx, fy, cx, cy = camera.params[:4]\n",
    "    K = np.array([[fx, 0, cx],\n",
    "                  [0, fy, cy],\n",
    "                  [0,  0,  1]])\n",
    "    return K, int(camera.width), int(camera.height)\n",
    "\n",
    "def load_extrinsics(image):\n",
    "    R = image.qvec2rotmat()\n",
    "    t = image.tvec.reshape(3, 1)\n",
    "    Rt = np.eye(4)\n",
    "    Rt[:3, :3] = R\n",
    "    Rt[:3, 3] = t[:, 0]\n",
    "    return np.linalg.inv(Rt)\n",
    "\n",
    "def render_scene(mesh, K, width, height, pose):\n",
    "    scene = pyrender.Scene(bg_color=[0, 0, 0, 0])\n",
    "    scene.add(mesh)\n",
    "\n",
    "    # Add directional light\n",
    "    light = pyrender.DirectionalLight(color=np.ones(3), intensity=3.0)\n",
    "    scene.add(light, pose=pose)  # nh sng theo hng nhn camera\n",
    "\n",
    "\n",
    "    camera = pyrender.IntrinsicsCamera(\n",
    "        fx=K[0, 0], fy=K[1, 1],\n",
    "        cx=K[0, 2], cy=K[1, 2],\n",
    "        znear=0.01, zfar=500.0  #  tng frustrum cho an ton\n",
    "    )\n",
    "\n",
    "    # Flip t COLMAP sang OpenGL\n",
    "    flip_transform = np.eye(4)\n",
    "    flip_transform[1, 1] = -1\n",
    "    flip_transform[2, 2] = -1\n",
    "    pose = pose @ flip_transform\n",
    "\n",
    "    # Thng tin camera\n",
    "    position = pose[:3, 3]\n",
    "    forward = -pose[:3, 2]\n",
    "    up = pose[:3, 1]\n",
    "    print(\" Camera position:\", position)\n",
    "    print(\"  Forward direction:\", forward)\n",
    "    print(\" Up direction:\", up)\n",
    "    print(\" Camera pose:\\n\", pose)\n",
    "\n",
    "    scene.add(camera, pose=pose)\n",
    "\n",
    "\n",
    "\n",
    "    renderer = pyrender.OffscreenRenderer(viewport_width=width, viewport_height=height)\n",
    "    color, _ = renderer.render(scene)\n",
    "    renderer.delete()\n",
    "    return color\n",
    "\n",
    "def main():\n",
    "    # Paths\n",
    "    sparse_dir = \"/Volumes/Projects/3drn/data/xe_F1_khan_60_test2/test\"\n",
    "    ply_file = \"/Volumes/Projects/3drn/data/new_project_xeF1_100/dense/0/xe_F1_100_chualoc.obj\"\n",
    "    output_image = \"render_test.png\"\n",
    "\n",
    "    # Load COLMAP camera & image\n",
    "    cameras = read_cameras_binary(os.path.join(sparse_dir, \"cameras.bin\"))\n",
    "    images = read_images_binary(os.path.join(sparse_dir, \"images.bin\"))\n",
    "\n",
    "    image = list(images.values())[0]\n",
    "    camera = cameras[image.camera_id]\n",
    "\n",
    "    K, width, height = load_intrinsics(camera)\n",
    "    pose = load_extrinsics(image)\n",
    "\n",
    "    # Load mesh bng Trimesh\n",
    "    mesh_trimesh = trimesh.load(ply_file)\n",
    "    if isinstance(mesh_trimesh, trimesh.Scene):\n",
    "        mesh_trimesh = mesh_trimesh.dump(concatenate=True)\n",
    "\n",
    "    # Chuyn sang Open3D  tnh bounding box\n",
    "    mesh_o3d = o3d.geometry.TriangleMesh()\n",
    "    mesh_o3d.vertices = o3d.utility.Vector3dVector(mesh_trimesh.vertices)\n",
    "    mesh_o3d.triangles = o3d.utility.Vector3iVector(mesh_trimesh.faces)\n",
    "    mesh_o3d.compute_vertex_normals()\n",
    "\n",
    "    bbox = mesh_o3d.get_axis_aligned_bounding_box()\n",
    "    print(\" Mesh bounding box:\")\n",
    "    print(\"   Min:\", bbox.get_min_bound())\n",
    "    print(\"   Max:\", bbox.get_max_bound())\n",
    "    print(\"   Center:\", bbox.get_center())\n",
    "\n",
    "    # Tnh khong cch t camera n model\n",
    "    camera_pos = pose[:3, 3]\n",
    "    model_center = bbox.get_center()\n",
    "    dist = norm(model_center - camera_pos)\n",
    "    print(f\" Distance camera  model center: {dist:.2f} units\")\n",
    "\n",
    "    #  (Tu chn) scale m hnh nu cn\n",
    "    # mesh_o3d.scale(1.5, center=model_center)\n",
    "\n",
    "    # Tr li v dng Trimesh  dng vi Pyrender\n",
    "    mesh_for_render = trimesh.Trimesh(vertices=np.asarray(mesh_o3d.vertices),\n",
    "                                      faces=np.asarray(mesh_o3d.triangles))\n",
    "    mesh = pyrender.Mesh.from_trimesh(mesh_for_render)\n",
    "\n",
    "    # Render\n",
    "    color = render_scene(mesh, K, width, height, pose)\n",
    "    cv2.imwrite(output_image, cv2.cvtColor(color, cv2.COLOR_RGB2BGR))\n",
    "    print(\" Render saved to\", output_image)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fx: 1146.4364194057184  - fy: 1146.4364194057184  - cx: 640.0  - cy: 360.0\n",
      " Intrinsic matrix K:\n",
      " [[1.14643642e+03 0.00000000e+00 6.40000000e+02]\n",
      " [0.00000000e+00 1.14643642e+03 3.60000000e+02]\n",
      " [0.00000000e+00 0.00000000e+00 1.00000000e+00]]\n",
      " Mesh bounding box:\n",
      "   Min: [-1.6425467  0.8469951  1.4751472]\n",
      "   Max: [1.876085  3.3991566 3.9150784]\n",
      "   Center: [0.11676915 2.12307585 2.6951128 ]\n",
      " Distance camera  model center: 4.68 units\n",
      " Camera position: [-0.24831919  2.1123566  -1.97424914]\n",
      "  Forward direction: [0.03051526 0.00633834 0.9995142 ]\n",
      " Up direction: [ 0.05172704 -0.99864995  0.00475363]\n",
      " Camera pose:\n",
      " [[ 0.99819494  0.05172704 -0.03051526 -0.24831919]\n",
      " [ 0.05155685 -0.99864995 -0.00633834  2.1123566 ]\n",
      " [-0.03080192  0.00475363 -0.9995142  -1.97424914]\n",
      " [ 0.          0.          0.          1.        ]]\n",
      " Render saved to render_test.png\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pyrender\n",
    "import trimesh\n",
    "import open3d as o3d\n",
    "from colmap.scripts.python.read_write_model import read_images_binary, read_cameras_binary\n",
    "from numpy.linalg import norm\n",
    "\n",
    "def load_intrinsics(camera):\n",
    "    model = camera.model\n",
    "\n",
    "    if model in ['SIMPLE_PINHOLE', 'SIMPLE_RADIAL']:\n",
    "        f, cx, cy = camera.params[:3]\n",
    "        fx = fy = f\n",
    "    elif model == 'PINHOLE':\n",
    "        fx, fy, cx, cy = camera.params[:4]\n",
    "    else:\n",
    "        raise ValueError(f\" Unsupported camera model: {model}\")\n",
    "\n",
    "    K = np.array([[fx, 0, cx],\n",
    "                  [0, fy, cy],\n",
    "                  [0,  0,  1]])\n",
    "    width, height = int(camera.width), int(camera.height)\n",
    "\n",
    "    print(f\"fx: {fx}  - fy: {fy}  - cx: {cx}  - cy: {cy}\")\n",
    "    if abs(cx - width / 2) > width * 0.1 or abs(cy - height / 2) > height * 0.1:\n",
    "        print(\"  Warning: cx, cy lch xa trung tm nh. Kim tra li ni ti COLMAP hoc nh  resize.\")\n",
    "\n",
    "    print(\" Intrinsic matrix K:\\n\", K)\n",
    "    return K, width, height\n",
    "\n",
    "def load_extrinsics(image):\n",
    "    R = image.qvec2rotmat()\n",
    "    t = image.tvec.reshape(3, 1)\n",
    "    Rt = np.eye(4)\n",
    "    Rt[:3, :3] = R\n",
    "    Rt[:3, 3] = t[:, 0]\n",
    "    return np.linalg.inv(Rt)\n",
    "\n",
    "def render_scene(mesh, K, width, height, pose):\n",
    "    # scene = pyrender.Scene(bg_color=[0, 0, 0, 0])\n",
    "    scene = pyrender.Scene(bg_color=[0, 0, 0, 0], ambient_light=[0.4, 0.4, 0.4])\n",
    "    scene.add(mesh)\n",
    "\n",
    "    # Add directional light\n",
    "    light = pyrender.DirectionalLight(color=np.ones(3), intensity=3.0)\n",
    "    scene.add(light, pose=pose)\n",
    "\n",
    "    # Add camera\n",
    "    camera = pyrender.IntrinsicsCamera(\n",
    "        fx=K[0, 0], fy=K[1, 1],\n",
    "        cx=K[0, 2], cy=K[1, 2],\n",
    "        znear=0.01, zfar=500.0\n",
    "    )\n",
    "\n",
    "    # Convert pose: COLMAP  OpenGL\n",
    "    flip_transform = np.eye(4)\n",
    "    flip_transform[1, 1] = -1\n",
    "    flip_transform[2, 2] = -1\n",
    "    pose = pose @ flip_transform\n",
    "\n",
    "    # Debug camera pose\n",
    "    position = pose[:3, 3]\n",
    "    forward = -pose[:3, 2]\n",
    "    up = pose[:3, 1]\n",
    "    print(\" Camera position:\", position)\n",
    "    print(\"  Forward direction:\", forward)\n",
    "    print(\" Up direction:\", up)\n",
    "    print(\" Camera pose:\\n\", pose)\n",
    "\n",
    "    scene.add(camera, pose=pose)\n",
    "\n",
    "    # Optional: Add coordinate axis for debugging\n",
    "    # axis = pyrender.Mesh.from_trimesh(trimesh.creation.axis(origin_size=0.1))\n",
    "    # scene.add(axis)\n",
    "\n",
    "    renderer = pyrender.OffscreenRenderer(viewport_width=width, viewport_height=height)\n",
    "    color, _ = renderer.render(scene)\n",
    "    renderer.delete()\n",
    "    return color\n",
    "\n",
    "def main():\n",
    "    # Paths\n",
    "    sparse_dir = \"/Volumes/Projects/3drn/data/xe_F1_khan_60_test2/test\"\n",
    "    ply_file = \"/Volumes/Projects/3drn/data/new_project_xeF1_100/dense/0/xe_F1_100_chualoc.obj\"\n",
    "    output_image = \"render_test.png\"\n",
    "\n",
    "    # Load COLMAP data\n",
    "    cameras = read_cameras_binary(os.path.join(sparse_dir, \"cameras.bin\"))\n",
    "    images = read_images_binary(os.path.join(sparse_dir, \"images.bin\"))\n",
    "    image = list(images.values())[0]\n",
    "    camera = cameras[image.camera_id]\n",
    "\n",
    "    # Intrinsics & extrinsics\n",
    "    K, width, height = load_intrinsics(camera)\n",
    "    pose = load_extrinsics(image)\n",
    "\n",
    "    # Load mesh\n",
    "    mesh_trimesh = trimesh.load(ply_file)\n",
    "    if isinstance(mesh_trimesh, trimesh.Scene):\n",
    "        mesh_trimesh = mesh_trimesh.dump(concatenate=True)\n",
    "\n",
    "    # Convert to Open3D for bounding box\n",
    "    mesh_o3d = o3d.geometry.TriangleMesh()\n",
    "    mesh_o3d.vertices = o3d.utility.Vector3dVector(mesh_trimesh.vertices)\n",
    "    mesh_o3d.triangles = o3d.utility.Vector3iVector(mesh_trimesh.faces)\n",
    "    mesh_o3d.compute_vertex_normals()\n",
    "\n",
    "    bbox = mesh_o3d.get_axis_aligned_bounding_box()\n",
    "    print(\" Mesh bounding box:\")\n",
    "    print(\"   Min:\", bbox.get_min_bound())\n",
    "    print(\"   Max:\", bbox.get_max_bound())\n",
    "    print(\"   Center:\", bbox.get_center())\n",
    "\n",
    "    # Distance camera  mesh center\n",
    "    camera_pos = pose[:3, 3]\n",
    "    model_center = bbox.get_center()\n",
    "    dist = norm(model_center - camera_pos)\n",
    "    print(f\" Distance camera  model center: {dist:.2f} units\")\n",
    "\n",
    "    # (Optional) scale if model too small\n",
    "    # mesh_o3d.scale(1.5, center=model_center)\n",
    "\n",
    "    # Convert back to Trimesh\n",
    "    mesh_for_render = trimesh.Trimesh(vertices=np.asarray(mesh_o3d.vertices),\n",
    "                                      faces=np.asarray(mesh_o3d.triangles))\n",
    "    mesh = pyrender.Mesh.from_trimesh(mesh_for_render)\n",
    "\n",
    "\n",
    "\n",
    "    # Render\n",
    "    color = render_scene(mesh, K, width, height, pose)\n",
    "    cv2.imwrite(output_image, cv2.cvtColor(color, cv2.COLOR_RGB2BGR))\n",
    "    print(\" Render saved to\", output_image)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fx: 1146.4364194057184  - fy: 1146.4364194057184  - cx: 640.0  - cy: 360.0\n",
      " Intrinsic matrix K:\n",
      " [[1.14643642e+03 0.00000000e+00 6.40000000e+02]\n",
      " [0.00000000e+00 1.14643642e+03 3.60000000e+02]\n",
      " [0.00000000e+00 0.00000000e+00 1.00000000e+00]]\n",
      " Mesh bounding box:\n",
      "   Min: [-1.6425467  0.8469951  1.4751472]\n",
      "   Max: [1.876085  3.3991566 3.9150784]\n",
      "   Center: [0.11676915 2.12307585 2.6951128 ]\n",
      " Distance camera  model center: 4.68 units\n",
      " Camera position: [-0.24831919  2.1123566  -1.97424914]\n",
      "  Forward direction: [0.03051526 0.00633834 0.9995142 ]\n",
      " Up direction: [ 0.05172704 -0.99864995  0.00475363]\n",
      " Camera pose:\n",
      " [[ 0.99819494  0.05172704 -0.03051526 -0.24831919]\n",
      " [ 0.05155685 -0.99864995 -0.00633834  2.1123566 ]\n",
      " [-0.03080192  0.00475363 -0.9995142  -1.97424914]\n",
      " [ 0.          0.          0.          1.        ]]\n",
      " Render saved to render_test.png\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pyrender\n",
    "import trimesh\n",
    "import open3d as o3d\n",
    "from colmap.scripts.python.read_write_model import read_images_binary, read_cameras_binary\n",
    "from numpy.linalg import norm\n",
    "\n",
    "def load_intrinsics(camera):\n",
    "    model = camera.model\n",
    "\n",
    "    if model in ['SIMPLE_PINHOLE', 'SIMPLE_RADIAL']:\n",
    "        f, cx, cy = camera.params[:3]\n",
    "        fx = fy = f\n",
    "        if cy < 1e-2:\n",
    "            print(\" Detected invalid cy ( 0), overriding to image center.\")\n",
    "            cy = camera.height / 2\n",
    "    elif model == 'PINHOLE':\n",
    "        fx, fy, cx, cy = camera.params[:4]\n",
    "    else:\n",
    "        raise ValueError(f\" Unsupported camera model: {model}\")\n",
    "\n",
    "    K = np.array([[fx, 0, cx],\n",
    "                  [0, fy, cy],\n",
    "                  [0,  0,  1]])\n",
    "    width, height = int(camera.width), int(camera.height)\n",
    "\n",
    "    print(f\"fx: {fx}  - fy: {fy}  - cx: {cx}  - cy: {cy}\")\n",
    "    if abs(cx - width / 2) > width * 0.1 or abs(cy - height / 2) > height * 0.1:\n",
    "        print(\"  Warning: cx, cy lch xa trung tm nh. Kim tra li ni ti COLMAP hoc nh  resize.\")\n",
    "\n",
    "    print(\" Intrinsic matrix K:\\n\", K)\n",
    "    return K, width, height\n",
    "\n",
    "def load_extrinsics(image):\n",
    "    R = image.qvec2rotmat()\n",
    "    t = image.tvec.reshape(3, 1)\n",
    "    Rt = np.eye(4)\n",
    "    Rt[:3, :3] = R\n",
    "    Rt[:3, 3] = t[:, 0]\n",
    "    return np.linalg.inv(Rt)\n",
    "\n",
    "def render_scene(mesh, K, width, height, pose):\n",
    "    # Scene with ambient light\n",
    "    scene = pyrender.Scene(bg_color=[0, 0, 0, 0], ambient_light=[0.4, 0.4, 0.4])\n",
    "    scene.add(mesh)\n",
    "\n",
    "    # Add fixed-directional light (from above)\n",
    "    light = pyrender.DirectionalLight(color=np.ones(3), intensity=3.0)\n",
    "    light_pose = np.eye(4)\n",
    "    light_pose[:3, 3] = [0, 5, 0]\n",
    "    scene.add(light, pose=light_pose)\n",
    "\n",
    "    # Add camera\n",
    "    camera = pyrender.IntrinsicsCamera(\n",
    "        fx=K[0, 0], fy=K[1, 1],\n",
    "        cx=K[0, 2], cy=K[1, 2],\n",
    "        znear=0.01, zfar=500.0\n",
    "    )\n",
    "\n",
    "    # Convert pose: COLMAP  OpenGL\n",
    "    flip_transform = np.eye(4)\n",
    "    flip_transform[1, 1] = -1\n",
    "    flip_transform[2, 2] = -1\n",
    "    pose_gl = pose @ flip_transform\n",
    "\n",
    "    # Debug camera pose\n",
    "    position = pose_gl[:3, 3]\n",
    "    forward = -pose_gl[:3, 2]\n",
    "    up = pose_gl[:3, 1]\n",
    "    print(\" Camera position:\", position)\n",
    "    print(\"  Forward direction:\", forward)\n",
    "    print(\" Up direction:\", up)\n",
    "    print(\" Camera pose:\\n\", pose_gl)\n",
    "\n",
    "    scene.add(camera, pose=pose_gl)\n",
    "\n",
    "    # Optional debug axis\n",
    "    # axis = pyrender.Mesh.from_trimesh(trimesh.creation.axis(origin_size=0.1))\n",
    "    # scene.add(axis)\n",
    "\n",
    "    renderer = pyrender.OffscreenRenderer(viewport_width=width, viewport_height=height)\n",
    "    color, _ = renderer.render(scene)\n",
    "    renderer.delete()\n",
    "    return color\n",
    "\n",
    "def main():\n",
    "    # Paths\n",
    "    sparse_dir = \"/Volumes/Projects/3drn/data/xe_F1_khan_60_test2/test\"\n",
    "    ply_file = \"/Volumes/Projects/3drn/data/new_project_xeF1_100/dense/0/xe_F1_100_chualoc.obj\"\n",
    "    output_image = \"render_test.png\"\n",
    "\n",
    "    # Load COLMAP data\n",
    "    cameras = read_cameras_binary(os.path.join(sparse_dir, \"cameras.bin\"))\n",
    "    images = read_images_binary(os.path.join(sparse_dir, \"images.bin\"))\n",
    "    image = list(images.values())[0]\n",
    "    camera = cameras[image.camera_id]\n",
    "\n",
    "    # Intrinsics & extrinsics\n",
    "    K, width, height = load_intrinsics(camera)\n",
    "    pose = load_extrinsics(image)\n",
    "\n",
    "    # Load mesh\n",
    "    mesh_trimesh = trimesh.load(ply_file)\n",
    "    if isinstance(mesh_trimesh, trimesh.Scene):\n",
    "        mesh_trimesh = mesh_trimesh.dump(concatenate=True)\n",
    "\n",
    "    # Convert to Open3D for bounding box\n",
    "    mesh_o3d = o3d.geometry.TriangleMesh()\n",
    "    mesh_o3d.vertices = o3d.utility.Vector3dVector(mesh_trimesh.vertices)\n",
    "    mesh_o3d.triangles = o3d.utility.Vector3iVector(mesh_trimesh.faces)\n",
    "    mesh_o3d.compute_vertex_normals()\n",
    "\n",
    "    bbox = mesh_o3d.get_axis_aligned_bounding_box()\n",
    "    print(\" Mesh bounding box:\")\n",
    "    print(\"   Min:\", bbox.get_min_bound())\n",
    "    print(\"   Max:\", bbox.get_max_bound())\n",
    "    print(\"   Center:\", bbox.get_center())\n",
    "\n",
    "    # Distance camera  mesh center\n",
    "    camera_pos = pose[:3, 3]\n",
    "    model_center = bbox.get_center()\n",
    "    dist = norm(model_center - camera_pos)\n",
    "    print(f\" Distance camera  model center: {dist:.2f} units\")\n",
    "\n",
    "    # Optional scaling\n",
    "    # mesh_o3d.scale(1.5, center=model_center)\n",
    "\n",
    "    # Convert back to Trimesh for rendering\n",
    "    mesh_for_render = trimesh.Trimesh(vertices=np.asarray(mesh_o3d.vertices),\n",
    "                                      faces=np.asarray(mesh_o3d.triangles))\n",
    "\n",
    "    ## Create Pyrender mesh with double_sided to avoid culling issues\n",
    "    # mesh = pyrender.Mesh.from_trimesh(mesh_for_render, smooth=False, double_sided=True)\n",
    "    \n",
    "    # To bn double-sided th cng\n",
    "    mesh_for_render_ds = make_mesh_double_sided(mesh_for_render)\n",
    "    mesh = pyrender.Mesh.from_trimesh(mesh_for_render_ds, smooth=False)\n",
    "\n",
    "    # Render\n",
    "    color = render_scene(mesh, K, width, height, pose)\n",
    "    cv2.imwrite(output_image, cv2.cvtColor(color, cv2.COLOR_RGB2BGR))\n",
    "    print(\" Render saved to\", output_image)\n",
    "\n",
    "def make_mesh_double_sided(tri_mesh: trimesh.Trimesh) -> trimesh.Trimesh:\n",
    "    \"\"\"\n",
    "    To mesh vi c mt trc v sau  trnh culling trong Pyrender.\n",
    "    \"\"\"\n",
    "    faces_back = tri_mesh.faces[:, ::-1]\n",
    "    faces = np.vstack([tri_mesh.faces, faces_back])\n",
    "    return trimesh.Trimesh(vertices=tri_mesh.vertices.copy(), faces=faces, process=False)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fx: 1146.4364194057184  - fy: 1146.4364194057184  - cx: 640.0  - cy: 360.0\n",
      " Intrinsic matrix K:\n",
      " [[1.14643642e+03 0.00000000e+00 6.40000000e+02]\n",
      " [0.00000000e+00 1.14643642e+03 3.60000000e+02]\n",
      " [0.00000000e+00 0.00000000e+00 1.00000000e+00]]\n",
      " Mesh bounding box:\n",
      "   Min: [-1.6425467  0.8469951  1.4751472]\n",
      "   Max: [1.876085  3.3991566 3.9150784]\n",
      "   Center: [0.11676915 2.12307585 2.6951128 ]\n",
      " Distance camera  model center: 4.68 units\n",
      " Has texture: False\n",
      " No texture found. Using double-sided mesh as fallback.\n",
      " Camera position: [-0.24831919  2.1123566  -1.97424914]\n",
      "  Forward direction: [0.03051526 0.00633834 0.9995142 ]\n",
      " Up direction: [ 0.05172704 -0.99864995  0.00475363]\n",
      " Camera pose:\n",
      " [[ 0.99819494  0.05172704 -0.03051526 -0.24831919]\n",
      " [ 0.05155685 -0.99864995 -0.00633834  2.1123566 ]\n",
      " [-0.03080192  0.00475363 -0.9995142  -1.97424914]\n",
      " [ 0.          0.          0.          1.        ]]\n",
      " Render saved to render_test.png\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pyrender\n",
    "import trimesh\n",
    "import open3d as o3d\n",
    "from colmap.scripts.python.read_write_model import read_images_binary, read_cameras_binary\n",
    "from numpy.linalg import norm\n",
    "\n",
    "def load_intrinsics(camera):\n",
    "    model = camera.model\n",
    "\n",
    "    if model in ['SIMPLE_PINHOLE', 'SIMPLE_RADIAL']:\n",
    "        f, cx, cy = camera.params[:3]\n",
    "        fx = fy = f\n",
    "        if cy < 1e-2:\n",
    "            print(\" Detected invalid cy ( 0), overriding to image center.\")\n",
    "            cy = camera.height / 2\n",
    "    elif model == 'PINHOLE':\n",
    "        fx, fy, cx, cy = camera.params[:4]\n",
    "    else:\n",
    "        raise ValueError(f\" Unsupported camera model: {model}\")\n",
    "\n",
    "    K = np.array([[fx, 0, cx],\n",
    "                  [0, fy, cy],\n",
    "                  [0,  0,  1]])\n",
    "    width, height = int(camera.width), int(camera.height)\n",
    "\n",
    "    print(f\"fx: {fx}  - fy: {fy}  - cx: {cx}  - cy: {cy}\")\n",
    "    if abs(cx - width / 2) > width * 0.1 or abs(cy - height / 2) > height * 0.1:\n",
    "        print(\"  Warning: cx, cy lch xa trung tm nh. Kim tra li ni ti COLMAP hoc nh  resize.\")\n",
    "\n",
    "    print(\" Intrinsic matrix K:\\n\", K)\n",
    "    return K, width, height\n",
    "\n",
    "def load_extrinsics(image):\n",
    "    R = image.qvec2rotmat()\n",
    "    t = image.tvec.reshape(3, 1)\n",
    "    Rt = np.eye(4)\n",
    "    Rt[:3, :3] = R\n",
    "    Rt[:3, 3] = t[:, 0]\n",
    "    return np.linalg.inv(Rt)\n",
    "\n",
    "def make_mesh_double_sided(tri_mesh: trimesh.Trimesh) -> trimesh.Trimesh:\n",
    "    faces_back = tri_mesh.faces[:, ::-1]\n",
    "    faces = np.vstack([tri_mesh.faces, faces_back])\n",
    "    return trimesh.Trimesh(vertices=tri_mesh.vertices.copy(), faces=faces, process=False)\n",
    "\n",
    "def render_scene(mesh, K, width, height, pose):\n",
    "    # scene = pyrender.Scene(bg_color=[0, 0, 0, 0], ambient_light=[0.4, 0.4, 0.4])\n",
    "    # scene = pyrender.Scene(bg_color=[0, 0, 0, 0])\n",
    "    scene = pyrender.Scene(bg_color=[0, 0, 0, 0], ambient_light=[0.3, 0.3, 0.3])    \n",
    "    scene.add(mesh)\n",
    "\n",
    "    # light = pyrender.DirectionalLight(color=np.ones(3), intensity=3.0)\n",
    "    # light_pose = np.eye(4)\n",
    "    # light_pose[:3, 3] = [0, 5, 0]\n",
    "    # scene.add(light, pose=light_pose)\n",
    "\n",
    "    camera = pyrender.IntrinsicsCamera(\n",
    "        fx=K[0, 0], fy=K[1, 1],\n",
    "        cx=K[0, 2], cy=K[1, 2],\n",
    "        znear=0.01, zfar=100.0\n",
    "    )\n",
    "\n",
    "    # Flip COLMAP to OpenGL convention\n",
    "    flip_transform = np.eye(4)\n",
    "    flip_transform[1, 1] = -1\n",
    "    flip_transform[2, 2] = -1\n",
    "    pose_gl = pose @ flip_transform\n",
    "\n",
    "    position = pose_gl[:3, 3]\n",
    "    forward = -pose_gl[:3, 2]\n",
    "    up = pose_gl[:3, 1]\n",
    "    print(\" Camera position:\", position)\n",
    "    print(\"  Forward direction:\", forward)\n",
    "    print(\" Up direction:\", up)\n",
    "    print(\" Camera pose:\\n\", pose_gl)\n",
    "\n",
    "    scene.add(camera, pose=pose_gl)\n",
    "\n",
    "    # Optional: show axis\n",
    "    # axis = pyrender.Mesh.from_trimesh(trimesh.creation.axis(origin_size=0.1))\n",
    "    # scene.add(axis)\n",
    "\n",
    "    renderer = pyrender.OffscreenRenderer(viewport_width=width, viewport_height=height)\n",
    "    color, _ = renderer.render(scene)\n",
    "    renderer.delete()\n",
    "    return color\n",
    "\n",
    "def main():\n",
    "    # Paths\n",
    "    sparse_dir = \"/Volumes/Projects/3drn/data/xe_F1_khan_60_test2/test\"\n",
    "    ply_file = \"/Volumes/Projects/3drn/data/new_project_xeF1_100/dense/0/xe_F1_100_chualoc.obj\"\n",
    "    output_image = \"render_test.png\"\n",
    "\n",
    "    # Load COLMAP data\n",
    "    cameras = read_cameras_binary(os.path.join(sparse_dir, \"cameras.bin\"))\n",
    "    images = read_images_binary(os.path.join(sparse_dir, \"images.bin\"))\n",
    "    image = list(images.values())[0]\n",
    "    camera = cameras[image.camera_id]\n",
    "\n",
    "    # Camera intrinsics & extrinsics\n",
    "    K, width, height = load_intrinsics(camera)\n",
    "    pose = load_extrinsics(image)\n",
    "\n",
    "    # Load mesh (.obj with .mtl and texture)\n",
    "    mesh_trimesh = trimesh.load(ply_file, force='mesh', process=True, maintain_order=True)\n",
    "    if isinstance(mesh_trimesh, trimesh.Scene):\n",
    "        mesh_trimesh = mesh_trimesh.dump(concatenate=True)\n",
    "\n",
    "    # Compute bounding box (optional)\n",
    "    mesh_o3d = o3d.geometry.TriangleMesh()\n",
    "    mesh_o3d.vertices = o3d.utility.Vector3dVector(mesh_trimesh.vertices)\n",
    "    mesh_o3d.triangles = o3d.utility.Vector3iVector(mesh_trimesh.faces)\n",
    "    mesh_o3d.compute_vertex_normals()\n",
    "\n",
    "    bbox = mesh_o3d.get_axis_aligned_bounding_box()\n",
    "    print(\" Mesh bounding box:\")\n",
    "    print(\"   Min:\", bbox.get_min_bound())\n",
    "    print(\"   Max:\", bbox.get_max_bound())\n",
    "    print(\"   Center:\", bbox.get_center())\n",
    "\n",
    "    camera_pos = pose[:3, 3]\n",
    "    dist = norm(bbox.get_center() - camera_pos)\n",
    "    print(f\" Distance camera  model center: {dist:.2f} units\")\n",
    "\n",
    "    # Check if texture available\n",
    "    has_texture = (\n",
    "        hasattr(mesh_trimesh.visual, 'material') and \n",
    "        getattr(mesh_trimesh.visual.material, 'image', None) is not None\n",
    "    )\n",
    "    print(f\" Has texture: {has_texture}\")\n",
    "\n",
    "    # Create Pyrender mesh\n",
    "    if has_texture:\n",
    "        mesh = pyrender.Mesh.from_trimesh(mesh_trimesh, smooth=False)\n",
    "    else:\n",
    "        print(\" No texture found. Using double-sided mesh as fallback.\")\n",
    "        mesh_ds = make_mesh_double_sided(mesh_trimesh)\n",
    "        mesh = pyrender.Mesh.from_trimesh(mesh_ds, smooth=False)\n",
    "\n",
    "    # Render\n",
    "    color = render_scene(mesh, K, width, height, pose)\n",
    "    cv2.imwrite(output_image, cv2.cvtColor(color, cv2.COLOR_RGB2BGR))\n",
    "    print(\" Render saved to\", output_image)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
